# Entity Cache

Storm maintains a transaction-scoped entity cache that optimizes database interactions. The cache is a pure performance optimization—it never changes the semantics of your transactions. What you read from the database is exactly what you would read without caching; the cache simply avoids redundant work.

## Design Principles

**Semantics-preserving:** The cache is carefully designed to align with your chosen transaction isolation level. At `READ_COMMITTED`, you see fresh data on every read—the cache won't return stale instances. At `REPEATABLE_READ` or in read-only transactions, returning cached instances is safe and matches what the database guarantees.

**Transparent:** You don't need to manage the cache. It's automatically scoped to the transaction and cleared on commit or rollback. There's no flush, no detach, no merge—just predictable behavior aligned with your isolation level.

**Multi-purpose:** The cache serves four complementary goals:

1. **Query optimization** — Avoid redundant database round-trips for the same entity
2. **Hydration optimization** — Skip entity construction when a cached instance exists
3. **Identity preservation** — Same database row returns the same object instance
4. **Dirty checking** — Track observed state for efficient updates

## How It Works

When you read an entity within a transaction, Storm stores it in a transaction-local cache keyed by primary key:

```
┌─────────────────────────────────────────────────────────────────────────┐
│                        Transaction Scope                                │
│                                                                         │
│   ┌──────────────┐                      ┌──────────────────────────┐    │
│   │   Database   │                      │      Entity Cache        │    │
│   └──────┬───────┘                      │  ┌────────┬───────────┐  │    │
│          │                              │  │   PK   │  Entity   │  │    │
│          │  SELECT                      │  ├────────┼───────────┤  │    │
│          ▼                              │  │   1    │  User(1)  │  │    │
│   ┌──────────────┐    cache write       │  │   2    │  User(2)  │  │    │
│   │  User(id=1)  │ ─────────────────────▶  │   42   │  City(42) │  │    │
│   └──────────────┘                      │  └────────┴───────────┘  │    │
│                                         └──────────────────────────┘    │
│                                                    │                    │
│   ┌──────────────┐    cache read                   │                    │
│   │ findById(1)  │ ◀───────────────────────────────┘                    │
│   └──────────────┘    (no SQL)                                          │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## Cache Behavior

Whether Storm returns cached instances depends on isolation level and read-only status:

| Condition | Cache Write | Cache Read |
|-----------|-------------|------------|
| `READ_COMMITTED` or lower (read-write) | If dirty checking enabled | No |
| `REPEATABLE_READ` or higher | Yes | Yes |
| Read-only transaction (any isolation) | Yes | Yes |

At `READ_COMMITTED` in a read-write transaction, Storm fetches fresh data on every read. At `REPEATABLE_READ` or in read-only transactions, cached instances are returned. This matches what the database guarantees at each isolation level.

---

## Query Optimization

### Repository Lookups

Repository methods that fetch by primary key check the cache first:

```kotlin
transaction {
    val user = userRepository.findById(1)    // Database query, result cached

    // ... other operations ...

    val sameUser = userRepository.findById(1) // Cache hit, no query
    // user === sameUser (same instance at REPEATABLE_READ+)
}
```

This applies to:
- `findById()` / `getById()`
- `findByRef()` / `getByRef()`
- `selectById()` / `selectByRef()`

### Ref Resolution

When you call `fetch()` on a `Ref`, Storm checks the cache before querying:

```kotlin
transaction {
    val order = orderRepository.findById(orderId)

    // If the customer was already loaded in this transaction,
    // this returns the cached instance without a query
    val customer = order.customer.fetch()
}
```

This is particularly useful when navigating entity graphs where the same entity might be referenced multiple times.

### Select Operations

When selecting multiple entities, Storm queries only for cache misses:

```kotlin
transaction {
    // Load some users
    val user1 = userRepository.findById(1)  // Cached
    val user2 = userRepository.findById(2)  // Cached

    // Select users 1, 2, 3, 4, 5
    val users = userRepository.select(listOf(1, 2, 3, 4, 5))
    // Only queries for IDs 3, 4, 5 - returns cached instances for 1, 2
}
```

---

## Entity Identity

At `REPEATABLE_READ` and above, the cache ensures consistent entity identity within a transaction:

```kotlin
transaction(isolation = REPEATABLE_READ) {
    val user1 = userRepository.findById(1)
    val user2 = userRepository.findById(1)

    // Same instance
    check(user1 === user2)

    // Also applies to entities loaded via relationships
    val order = orderRepository.findById(orderId)
    val orderUser = order.user.fetch()

    if (order.userId == 1) {
        check(orderUser === user1)  // Same instance
    }
}
```

This identity guarantee simplifies application logic—you can use reference equality (`===`) to check if two variables refer to the same database row.

---

## Cache Invalidation

The cache is invalidated when entities are mutated to ensure consistency with the database:

### After Mutations

Insert, update, upsert, and delete operations invalidate the cache entry for the affected entity:

```kotlin
transaction {
    val user = userRepository.findById(1)     // Cached

    userRepository.update(user.copy(name = "New Name"))
    // Cache entry invalidated

    val freshUser = userRepository.findById(1) // Database query
    // freshUser has the database state (including any trigger modifications)
}
```

Why invalidate rather than update? The database may modify data in ways not visible to the application:
- Triggers can change values after INSERT/UPDATE
- Version fields are incremented by the database
- Default values and computed columns
- `ON UPDATE CURRENT_TIMESTAMP` constraints

By invalidating, the next read fetches the actual persisted state.

### Raw SQL Mutations

When you execute raw SQL mutations, Storm cannot determine which entities were affected:

```kotlin
transaction {
    val user = userRepository.findById(1)   // Cached
    val city = cityRepository.findById(42)  // Cached

    // Raw SQL - Storm doesn't know what was affected
    orm.execute("UPDATE user SET status = 'inactive' WHERE last_login < ?", cutoffDate)

    // All caches cleared for safety
    val freshUser = userRepository.findById(1)  // Database query
}
```

To preserve cache efficiency, prefer using repository methods or typed templates that specify the entity type.

---

## Memory Management

The entity cache is scoped to a single transaction and automatically discarded when the transaction commits or rolls back. You don't need to manage cache lifecycle—it's tied to the transaction boundary.

Within a transaction, memory is managed automatically based on what your code is using:

- Entities you're actively using stay cached
- Entities you've moved past can be reclaimed
- Memory usage stays proportional to your working set

### Retention Modes

Configure retention behavior via system property:

```bash
-Dstorm.entityCache.retention=minimal   # Default
-Dstorm.entityCache.retention=aggressive
```

| Mode | Behavior | Use Case |
|------|----------|----------|
| `minimal` | Entries may be cleaned up when entity is no longer referenced | Most applications |
| `aggressive` | Entries retained more strongly | Streaming, DTO pipelines |

### Impact on Dirty Checking

If an entity's cache entry is cleaned up before you call `update()`, Storm falls back to a full-row update. This is correct but less optimal. If you observe frequent fallbacks, consider:

- Using `aggressive` retention
- Keeping references to entities until update
- Restructuring code to update sooner after reading

---

## Dirty Checking Integration

The entity cache stores observed state that enables dirty checking for efficient updates:

```kotlin
transaction {
    val user = userRepository.findById(1)  // State observed and cached

    // Modify the entity
    val updated = user.copy(name = "New Name")

    // Storm compares against cached state
    userRepository.update(updated)
    // With FIELD mode: UPDATE user SET name = ? WHERE id = ?
    // With ENTITY mode: Full row update, but skipped if unchanged
}
```

Cache writes for dirty checking occur at all isolation levels when dirty checking is enabled for the entity type. See [Dirty Checking & Update Modes](dirty-checking.md) for details on configuring update behavior.

---

## Transaction Boundaries

The entity cache is scoped to a single transaction. When the transaction commits or rolls back, all cached state is discarded.

### Nested Transactions

Cache behavior with nested transactions depends on propagation:

| Propagation | Cache Behavior |
|-------------|----------------|
| `REQUIRED`, `SUPPORTS`, `MANDATORY` | Shares parent's cache |
| `NESTED` | Shares parent's cache; cleared on savepoint rollback |
| `REQUIRES_NEW` | Fresh cache (separate transaction) |
| `NOT_SUPPORTED`, `NEVER` | Fresh cache (no transaction) |

```kotlin
transaction {
    val user = userRepository.findById(1)  // Cached in outer transaction

    transaction(propagation = NESTED) {
        val sameUser = userRepository.findById(1)  // Cache hit from outer
        // sameUser === user
    }

    transaction(propagation = REQUIRES_NEW) {
        val differentUser = userRepository.findById(1)  // Fresh query, new cache
        // differentUser !== user (different transaction, different instance)
    }
}
```

---

## Configuration Reference

| Property | Default | Description |
|----------|---------|-------------|
| `storm.entityCache.retention` | `minimal` | Cache retention: `minimal` or `aggressive` |

---

## Query-Level Identity

Even without transaction-level caching, Storm preserves entity identity within a single query result. When the same entity appears multiple times in one query (e.g., through joins), Storm interns these to the same object instance.

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           Query Result Set                                  │
│                                                                             │
│   SELECT o.*, c.* FROM orders o JOIN customers c ON o.customer_id = c.id    │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │  Row 1: Order(id=1, customer_id=42) │ Customer(id=42, name="Alice") │   │
│   │  Row 2: Order(id=2, customer_id=42) │ Customer(id=42, name="Alice") │   │
│   │  Row 3: Order(id=3, customer_id=99) │ Customer(id=99, name="Bob")   │   │
│   └─────────────────────────────────────────────────────────────────────┘   │
│                              │                                              │
│                              ▼                                              │
│                  ┌───────────────────────┐                                  │
│                  │       Interner        │                                  │
│                  │  ┌────────┬────────┐  │                                  │
│                  │  │   PK   │ Entity │  │                                  │
│                  │  ├────────┼────────┤  │                                  │
│                  │  │   42   │ ─────────────▶ Customer(42)                  │
│                  │  │   99   │ ─────────────▶ Customer(99)                  │
│                  │  └────────┴────────┘  │                                  │
│                  └───────────────────────┘                                  │
│                              │                                              │
│                              ▼                                              │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │  Result:                                                            │   │
│   │    Order(1) ──▶ Customer(42) ◀── same instance                      │   │
│   │    Order(2) ──▶ Customer(42) ◀──┘                                   │   │
│   │    Order(3) ──▶ Customer(99)                                        │   │
│   └─────────────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────────────┘
```

The diagram shows a join query returning three orders with their customers. Customer 42 ("Alice") appears in two rows—once for Order 1 and once for Order 2. Without interning, Storm would construct two separate `Customer` objects with identical data, wasting memory and breaking identity checks.

Instead, Storm uses a query-scoped interner that tracks entities by primary key as they're constructed. When Row 1 is processed, `Customer(42)` is constructed and stored in the interner. When Row 2 is processed, the interner recognizes that a `Customer` with PK 42 already exists and returns the same instance instead of constructing a new one.

The result: both `Order(1)` and `Order(2)` reference the exact same `Customer` object in memory. This happens automatically during result set hydration, regardless of isolation level.

**Memory-safe:** The interner only retains entities as long as your code holds onto them. Once you're done with an entity and release it, the interner won't prevent garbage collection. This makes streaming and flow-based processing safe: as you process and release entities, memory is reclaimed. You won't accumulate unbounded state when processing large result sets.

```kotlin
// Even at READ_COMMITTED in a read-write transaction:
val orders = orderRepository.findAll { Order_.status eq "pending" }

// If order1 and order2 have the same customer, they share the instance
val customer1 = orders[0].customer.fetch()
val customer2 = orders[1].customer.fetch()  // Same instance if same customer
```

**Why this matters:**
- **Memory efficiency** — Duplicate entities in a result set share one instance
- **Consistent identity** — Within a query, `===` works as expected for same-row entities

**Relationship with transaction-level caching:**
- At `READ_COMMITTED` (read-write): Identity preserved within each query, but separate queries may return different instances
- At `REPEATABLE_READ`+ or read-only: Query-level identity is extended transaction-wide via the cache

---

## Best Practices

### 1. Use Read-Only Transactions for Read-Heavy Workloads

Read-only transactions get full cache benefits at any isolation level, without the locking overhead of higher isolation levels:

```kotlin
transaction(readOnly = true) {
    // Full cache benefits: lookups, identity preservation, no redundant queries
    val user = userRepository.findById(1)
    val sameUser = userRepository.findById(1)  // Cache read, same instance
}
```

### 2. Leverage Ref.fetch() Caching

When navigating relationships, `Ref.fetch()` automatically uses the cache:

```kotlin
transaction {
    // Load orders with their users
    val orders = orderRepository.findAll { Order_.status eq "pending" }

    // If multiple orders share the same user, only one query per unique user
    orders.forEach { order ->
        val user = order.user.fetch()  // Cached after first fetch per user
        println("${order.id} belongs to ${user.name}")
    }
}
```

### 3. Batch Lookups for Cache Efficiency

When you need multiple entities, use batch lookups to optimize cache interaction:

```kotlin
transaction {
    // Efficient: single query for cache misses
    val users = userRepository.select(userIds)

    // Less efficient: N queries (though cached results help)
    val users = userIds.map { userRepository.findById(it) }
}
```

### 4. Keep Transactions Focused

Since the cache is transaction-scoped, long-running transactions accumulate cached entities. Keep transactions focused on specific operations to maintain predictable memory usage.
