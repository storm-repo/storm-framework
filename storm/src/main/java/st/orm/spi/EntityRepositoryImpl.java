/*
 * Copyright 2024 the original author or authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package st.orm.spi;

import jakarta.annotation.Nonnull;
import jakarta.annotation.Nullable;
import st.orm.BatchCallback;
import st.orm.NoResultException;
import st.orm.NonUniqueResultException;
import st.orm.OptimisticLockException;
import st.orm.PersistenceException;
import st.orm.PreparedQuery;
import st.orm.repository.Column;
import st.orm.repository.Entity;
import st.orm.repository.EntityRepository;
import st.orm.repository.Model;
import st.orm.template.ORMRepositoryTemplate;

import java.util.List;
import java.util.function.Supplier;
import java.util.stream.IntStream;
import java.util.stream.Stream;
import java.util.stream.StreamSupport;

import static java.lang.StringTemplate.RAW;
import static st.orm.template.QueryBuilder.slice;

/**
 */
@SuppressWarnings("DuplicatedCode")
public class EntityRepositoryImpl<E extends Record & Entity<ID>, ID>
        extends BaseRepositoryImpl<E, ID>
        implements EntityRepository<E, ID> {

    private static final ORMReflection REFLECTION = Providers.getORMReflection();

    protected final int defaultBatchSize;
    protected final boolean autoGeneratedPrimaryKey;

    public EntityRepositoryImpl(@Nonnull ORMRepositoryTemplate orm, @Nonnull Model<E, ID> model) {
        super(orm, model);
        this.defaultBatchSize = 1000;
        this.autoGeneratedPrimaryKey = model.columns().stream()
                .filter(Column::primaryKey)
                .anyMatch(Column::autoGenerated);
    }

    protected boolean isDefault(@Nonnull E entity) {
        return REFLECTION.isDefaultValue(entity.id());
    }

    @Override
    public Model<E, ID> model() {
        return model;
    }

    /**
     * Inserts an entity into the database.
     *
     * <p>This method adds a new entity to the database. It ensures that the entity is persisted according to the defined
     * database constraints and entity model. It's critical for the entity to be fully initialized as per the entity
     * model requirements.</p>
     *
     * @param entity the entity to insert. The entity must satisfy all model constraints.
     * @throws PersistenceException if the insert operation fails. This can happen due to a variety of reasons,
     * including database constraints violations, connectivity issues, or if the entity parameter is null.
     */
    @Override
    public void insert(@Nonnull E entity) {
        var query = orm.query(RAW."""
                INSERT INTO \{model.type()}
                VALUES \{entity}""");
        if (query.executeUpdate() != 1) {
            throw new PersistenceException("Insert failed.");
        }
    }

    /**
     * Inserts an entity into the database and returns its primary key.
     *
     * <p>This method adds a new entity to the database and upon successful insertion, returns the primary key assigned to
     * the entity when the primary key is generated by the database (e.g., auto-incremented). Otherwise, if the primary
     * key is not generated by the database, the method returns an empty optional.</p>
     *
     * @param entity the entity to insert. The entity must satisfy all model constraints.
     * @return the generated primary key of the successfully inserted entity.
     * @throws PersistenceException if the insert operation fails for reasons such as database constraints violations,
     * connectivity issues, or if the entity parameter is null.
     */
    @Override
    public ID insertAndFetchId(@Nonnull E entity) {
        try (var query = orm.query(RAW."""
                INSERT INTO \{model.type()}
                VALUES \{entity}""").prepare()) {
            if (query.executeUpdate() != 1) {
                throw new PersistenceException("Insert failed.");
            }
            return singleResult(autoGeneratedPrimaryKey
                    ? query.getGeneratedKeys(model.primaryKeyType())
                    : Stream.of(entity.id()));
        }
    }

    /**
     * Inserts an entity into the database and retrieves it back.
     *
     * This method first inserts the entity into the database using the {@code insertAndFetchId} method,
     * which also fetches the primary key of the inserted entity. After insertion, it retrieves the
     * entity by its primary key using the {@code select} method. This ensures that the entity returned
     * includes all current fields from the database, especially useful if there are any triggers or
     * defaults set in the database that modify the data upon insertion.
     *
     * @param entity the entity to insert. Must not be null and must conform to the model constraints.
     * @return the newly inserted entity as it exists in the database after insertion.
     * @throws PersistenceException if there is an error during the insertion or fetch operation, such as
     *         a violation of database constraints or connectivity issues.
     */
    @Override
    public E insertAndFetch(@Nonnull E entity) {
        return select(insertAndFetchId(entity));
    }

    /**
     * Updates an existing entity in the database.
     *
     * <p>This method applies modifications to an existing entity within the database. It's essential
     * that the entity passed to this method already exists in the database and is properly identified
     * by its primary key. The method ensures that the entity's state is synchronized with the database,
     * reflecting any changes made to the entity's fields, according to the entity model constraints.</p>
     *
     * @param entity the entity to update. This entity must already exist in the database and must satisfy all model
     * constraints. The entity's state is updated in the database, and it's critical that the entity includes an
     * identifier (primary key) that matches an existing record.
     * @throws PersistenceException if the update operation fails. This can occur for several reasons, such as if the
     * entity does not exist in the database, if there are database constraints violations, connectivity issues, or if
     * the entity parameter is null.
     */
    @Override
    public void update(@Nonnull E entity) {
        var query = orm.query(RAW."""
                UPDATE \{model.type()}
                SET \{entity}
                WHERE \{entity}""");
        int result = query.executeUpdate();
        if (query.isVersionAware() && result == 0) {
            throw new OptimisticLockException("Update failed due to optimistic lock.");
        } else if (result != 1) {
            throw new PersistenceException("Update failed.");
        }
    }

    /**
     * Updates an existing entity in the database and retrieves the updated entity.
     *
     * This method first updates the entity in the database using the {@code update} method,
     * ensuring that any changes to the entity's fields are persisted. Following the update,
     * it retrieves the entity by its primary key using the {@code select} method to ensure the
     * returned entity reflects all current data from the database, including any changes that
     * might have been applied during the update process (e.g., through triggers).
     *
     * @param entity the entity to update. This entity must not be null, must already exist in the database,
     *        and must conform to the model constraints.
     * @return the updated entity as it exists in the database after the update.
     * @throws PersistenceException if there is an error during the update or retrieval operation, such as
     *         a violation of database constraints, connectivity issues, or if the entity does not exist.
     */
    @Override
    public E updateAndFetch(@Nonnull E entity) {
        update(entity);
        return select(entity.id());
    }

    private PersistenceException upsertNotAvailable() {
        return new PersistenceException("Upsert is not available for the default implementation.");
    }

    /**
     * Performs an upsert operation for a single entity into the database. If the entity already exists
     * (as determined by its primary key or unique constraints), it is updated; otherwise, a new entity is inserted.
     *
     * This method handles duplicates by executing a database-specific upsert operation, which may involve SQL
     * extensions or functions depending on the underlying database implementation.
     *
     * @param entity the entity to insert or update. Must not be null and must conform to the model constraints.
     * @throws PersistenceException if there is an error during the upsert operation, such as a violation of database
     *                              constraints, connectivity issues, or if the entity is null.
     */
    @Override
    public void upsert(@Nonnull E entity) {
        throw upsertNotAvailable();
    }

    /**
     * Performs an upsert operation for a single entity and fetches the primary key of the inserted or updated entity.
     * This is typically used when the primary keys are generated by the database (e.g., auto-increment IDs).
     *
     * The operation ensures that if an entity with a matching key exists, it is updated; otherwise, a new entity is
     * inserted. The primary key of the entity is then retrieved.
     *
     * @param entity the entity to insert or update. Must not be null and must conform to the model constraints.
     * @return the primary key of the upserted entity.
     * @throws PersistenceException if there is an error during the upsert or key retrieval operation, such as a
     *                              violation of database constraints, connectivity issues, or if the entity is null.
     */
    @Override
    public ID upsertAndFetchId(@Nonnull E entity) {
        throw upsertNotAvailable();
    }

    /**
     * Performs an upsert operation for a single entity and fetches the entity as stored in the database after the
     * operation. This method is useful to obtain the complete entity including any fields that may be generated or
     * modified by the database.
     *
     * @param entity the entity to insert or update. Must not be null and must conform to the model constraints.
     * @return the upserted entity, as retrieved from the database.
     * @throws PersistenceException if there is an error during the upsert or retrieval operation, such as a violation
     *                              of database constraints, connectivity issues, or if the entity is null.
     */
    @Override
    public E upsertAndFetch(@Nonnull E entity) {
        throw upsertNotAvailable();
    }

    /**
     * Deletes an entity from the database.
     *
     * <p>This method removes an existing entity from the database. It is important to ensure that the entity passed for
     * deletion exists in the database and is correctly identified by its primary key.</p>
     *
     * @param entity the entity to delete. The entity must exist in the database and should be correctly identified by
     * its primary key.
     * @throws PersistenceException if the deletion operation fails. Reasons for failure might include the entity not
     * being found in the database, violations of database constraints, connectivity issues, or if the entity parameter
     * is null.
     */
    @Override
    public void delete(@Nonnull E entity) {
        var query = orm.query(RAW."""
                DELETE FROM \{model.type()}
                WHERE \{entity}""");
        if (query.executeUpdate() != 1) {
            throw new PersistenceException("Delete failed.");
        }
    }

    /**
     * Deletes all entities from the database.
     *
     * <p>This method performs a bulk deletion operation, removing all instances of the entities managed by this
     * repository from the database.</p>
     *
     * @throws PersistenceException if the bulk deletion operation fails. Failure can occur for several reasons,
     * including but not limited to database access issues, transaction failures, or underlying database constraints
     * that prevent the deletion of certain records.
     */
    @Override
    public void deleteAll() {
        orm.query(RAW."DELETE FROM \{model.type()}").executeUpdate();
    }

    // List based methods. These methods operate in a single batch.

    /**
     * Inserts multiple entities in a single batch operation to optimize database performance and reduce load.
     *
     * <p>This method is designed to efficiently insert a collection of entities into the database by bundling them
     * into a single batch. This approach minimizes the number of database operations, significantly improving
     * performance and reducing the impact on database resources compared to inserting each entity individually.
     * It's particularly useful for bulk insertion tasks where numerous entities need to be persisted simultaneously.</p>
     *
     * @param entities the collection of entities to insert. Each entity in this collection must be fully initialized
     * and valid according to the entity model's constraints. The collection must not contain null elements.
     * @throws PersistenceException if the batch insert operation fails. This can be due to various reasons such as
     * violation of database constraints, connectivity issues, or invalid input parameters.
     */
    @Override
    public void insert(@Nonnull Iterable<E> entities) {
        insert(toStream(entities), defaultBatchSize);
    }

    /**
     * Inserts multiple entities in a single batch operation and returns their generated primary keys.
     *
     * <p>This method efficiently inserts a collection of entities into the database as a single batch, optimizing
     * performance and minimizing database load. Upon successful insertion, it returns the primary keys assigned to
     * the entities when the primary keys are generated by the database (e.g., auto-incremented).Otherwise, if the
     * primary keys are not generated by the database, the method returns an empty list.</p>
     *
     * @param entities the collection of entities to be inserted. Each entity must be fully initialized and adhere
     * to the entity model's constraints. The collection must not contain null elements.
     * @return the generated primary keys of the successfully inserted entities, or an empty list if the primary keys
     * are not generated by the database.
     * @throws PersistenceException if the batch insert operation fails. Failure can result from various issues,
     * including database constraints violations, connectivity problems, or invalid input parameters.
     */
    @Override
    public List<ID> insertAndFetchIds(@Nonnull Iterable<E> entities) {
        var bindVars = orm.createBindVars();
        try (var query = orm.query(RAW."""
                INSERT INTO \{model.type()}
                VALUES \{bindVars}""").prepare()) {
            return slice(toStream(entities), defaultBatchSize,
                    batch -> {
                        batch.stream().map(Record.class::cast).forEach(query::addBatch);
                        int[] result = query.executeBatch();
                        if (IntStream.of(result).anyMatch(r -> r != 1)) {
                            throw new PersistenceException("Batch insert failed.");
                        }
                        // Stream is closed by the batch operation.
                        return autoGeneratedPrimaryKey
                                ? query.getGeneratedKeys(model.primaryKeyType())
                                : batch.stream().map(Entity::id);
            }).toList();
        }
    }

    /**
     * Inserts multiple entities into the database and retrieves them back as a list.
     *
     * This method first inserts a collection of entities into the database using the {@code insertAndFetchIds} method,
     * which also fetches the primary keys of the inserted entities. After insertion, it retrieves the entities by their
     * primary keys using the {@code select} method. This ensures that the returned entities include all current fields
     * from the database, particularly useful if there are any database triggers or defaults that modify the data upon insertion.
     *
     * @param entities an iterable collection of entities to insert. Each entity must not be null and must conform to the model constraints.
     * @return a list of newly inserted entities as they exist in the database after insertion.
     * @throws PersistenceException if there is an error during the insertion or retrieval operation, such as
     *         a violation of database constraints, connectivity issues, or if any entity in the collection is null.
     */
    @Override
    public List<E> insertAndFetch(@Nonnull Iterable<E> entities) {
        return select(insertAndFetchIds(entities));
    }

    /**
     * Updates multiple entities in a single batch operation to optimize performance and reduce database load.
     *
     * <p>This method is designed to perform a bulk update on a collection of entities, applying changes to all
     * provided entities in one transaction. This batch approach significantly improves efficiency and reduces
     * the impact on database resources compared to updating each entity individually.</p>
     *
     * @param entities the collection of entities to update. Each entity in this collection must already exist in the
     * database and be fully initialized with the desired state changes. The entities must adhere to the entity model's
     * constraints and should be correctly identified by their primary keys. The collection must not contain null
     * elements.
     * @throws PersistenceException if the batch update operation fails. This can be due to a variety of reasons, such
     * as violation of database constraints, connectivity issues, or invalid input parameters.
     */
    @Override
    public void update(@Nonnull Iterable<E> entities) {
        update(toStream(entities), defaultBatchSize);
    }

    /**
     * Updates multiple entities in the database and retrieves the updated entities as a list.
     *
     * This method first updates a collection of entities in the database using the {@code update} method,
     * ensuring that any modifications to the entities' fields are persisted. Following the update,
     * it retrieves the entities by their primary keys using the {@code select} method to ensure the
     * returned entities reflect all current data from the database, including any changes that
     * might have been applied during the update process (e.g., through triggers).
     *
     * @param entities an iterable collection of entities to update. Each entity must not be null, must already exist in the database,
     *        and must conform to the model constraints.
     * @return a list of updated entities as they exist in the database after the update.
     * @throws PersistenceException if there is an error during the update or retrieval operation, such as
     *         a violation of database constraints, connectivity issues, or if any entity does not exist.
     */
    @Override
    public List<E> updateAndFetch(@Nonnull Iterable<E> entities) {
        update(entities);
        return select(StreamSupport.stream(entities.spliterator(), false).map(Entity::id).toList());
    }

    /**
     * Performs an upsert operation for multiple entities provided as an iterable in a single batch.
     *
     * @param entities an iterable of entities to upsert. Each entity must not be null and must conform to the model
     *                constraints.
     * @throws PersistenceException if there is an error during the upsert operation, such as a violation of database
     *                              constraints, connectivity issues, or if any entity in the iterable is null.
     */
    @Override
    public void upsert(@Nonnull Iterable<E> entities) {
        throw upsertNotAvailable();
    }

    /**
     * Performs an upsert operation for multiple entities in a single batch and fetches their primary keys.
     *
     * @param entities an iterable of entities to upsert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @return a list of primary keys of the upserted entities.
     * @throws PersistenceException if there is an error during the upsert or key retrieval operation, such as a
     *                              violation of database constraints, connectivity issues, or if any entity in the
     *                              iterable is null.
     */
    @Override
    public List<ID> upsertAndFetchIds(@Nonnull Iterable<E> entities) {
        throw upsertNotAvailable();
    }

    /**
     * Performs an upsert operation for multiple entities in a single batch and fetches the entities as stored in
     * the database after the upsert.
     *
     * @param entities an iterable of entities to upsert. Each entity must not be null and must conform to the model
     *                constraints.
     * @return a list of the upserted entities, as retrieved from the database.
     * @throws PersistenceException if there is an error during the upsert or retrieval operation, such as a violation
     *                              of database constraints, connectivity issues, or if any entity in the iterable is
     *                              null.
     */
    @Override
    public List<E> upsertAndFetch(@Nonnull Iterable<E> entities) {
        throw upsertNotAvailable();
    }

    /**
     * Deletes multiple entities in a single batch operation to optimize performance and reduce database load.
     *
     * <p>This method enables the efficient removal of a collection of entities from the database by processing
     * them as a single batch. Utilizing this batch deletion approach minimizes the number of individual transactions,
     * thereby reducing the impact on database resources and improving overall performance.</p>
     *
     * @param entities the collection of entities to be deleted. Each entity in this collection must exist in the
     * database and be correctly identified by its primary key. The collection must not contain null elements.
     * @throws PersistenceException if the batch delete operation fails. Reasons for failure might include the entities
     * not being found in the database, violations of database constraints, connectivity issues, or invalid input
     * parameters.
     */
    @Override
    public void delete(@Nonnull Iterable<E> entities) {
        delete(toStream(entities), defaultBatchSize);
    }

    // Stream based methods. These methods operate in multiple batches.

    /**
     * Inserts a stream of entities into the database using the default batch size.
     *
     * This method inserts entities provided in a stream, optimizing the insertion process by batching them
     * with a default size. This helps to reduce the number of database operations and can significantly improve
     * performance when inserting large numbers of entities.
     *
     * @param entities a stream of entities to insert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @throws PersistenceException if there is an error during the insertion operation, such as a violation of database
     *                              constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void insert(@Nonnull Stream<E> entities) {
        insert(entities, defaultBatchSize);
    }

    /**
     * Inserts a stream of entities into the database, with the insertion process divided into batches of the specified
     * size.
     *
     * This method inserts entities provided in a stream and uses the specified batch size for the insertion operation.
     * Batching the inserts can greatly enhance performance by minimizing the number of database interactions,
     * especially useful when dealing with large volumes of data.
     *
     * @param entities a stream of entities to insert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @param batchSize the size of the batches to use for the insertion operation. A larger batch size can improve
     *                  performance but may also increase the load on the database.
     * @throws PersistenceException if there is an error during the insertion operation, such as a violation of database
     *                              constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void insert(@Nonnull Stream<E> entities, int batchSize) {
        var bindVars = orm.createBindVars();
        try (var query = orm.query(RAW."""
                INSERT INTO \{model.type()}
                VALUES \{bindVars}""").prepare()) {
            slice(entities, batchSize).forEach(batch -> {
                batch.stream().map(Record.class::cast).forEach(query::addBatch);
                int[] result = query.executeBatch();
                if (IntStream.of(result).anyMatch(r -> r != 1)) {
                    throw new PersistenceException("Batch insert failed.");
                }
            });
        }
    }

    /**
     * Inserts a stream of entities into the database using the default batch size and returns a stream of their generated primary keys.
     *
     * This method facilitates the insertion of entities and fetches their primary keys immediately after insertion. This is
     * particularly useful when the primary keys are generated by the database (e.g., auto-increment fields). It uses the default
     * batch size to optimize the number of database interactions.
     *
     * @param entities a stream of entities to insert. Each entity must not be null and must conform to the model constraints.
     * @return a stream of primary keys for the inserted entities.
     * @throws PersistenceException if there is an error during the insertion or key retrieval operation, such as a violation
     *         of database constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void insertAndFetchIds(@Nonnull Stream<E> entities, @Nonnull BatchCallback<ID> callback) {
        insertAndFetchIds(entities, defaultBatchSize, callback);
    }

    /**
     * Inserts a stream of entities into the database using the default batch size and returns a stream of the inserted entities.
     *
     * This method inserts entities into the database and retrieves them immediately after insertion. It is useful for ensuring
     * that the returned entities reflect any database-generated values or defaults. The insertion and retrieval are performed using
     * the default batch size to optimize database performance.
     *
     * @param entities a stream of entities to insert. Each entity must not be null and must conform to the model constraints.
     * @return a stream of the inserted entities as they are stored in the database.
     * @throws PersistenceException if there is an error during the insertion or retrieval operation, such as a violation of
     *         database constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void insertAndFetch(@Nonnull Stream<E> entities, @Nonnull BatchCallback<E> callback) {
        insertAndFetch(entities, defaultBatchSize, callback);
    }

    /**
     * Inserts a stream of entities into the database with the insertion process divided into batches of the specified size,
     * and returns a stream of their generated primary keys.
     *
     * This method allows for efficient insertion of a large number of entities by batching them according to the specified batch
     * size. It also fetches the primary keys immediately after insertion, useful for entities with database-generated keys.
     *
     * @param entities a stream of entities to insert. Each entity must not be null and must conform to the model constraints.
     * @param batchSize the size of the batches to use for the insertion operation. A larger batch size can improve performance
     *                  but may also increase the load on the database.
     * @return a stream of primary keys for the inserted entities.
     * @throws PersistenceException if there is an error during the insertion or key retrieval operation, such as a violation
     *         of database constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void insertAndFetchIds(@Nonnull Stream<E> entities, int batchSize, @Nonnull BatchCallback<ID> callback) {
        var bindVars = orm.createBindVars();
        try (var query = orm.query(RAW."""
                INSERT INTO \{model.type()}
                VALUES \{bindVars}""").prepare()) {
            slice(entities, batchSize).forEach(batch -> {
                batch.stream().map(Record.class::cast).forEach(query::addBatch);
                int[] result = query.executeBatch();
                if (IntStream.of(result).anyMatch(r -> r != 1)) {
                    throw new PersistenceException("Batch insert failed.");
                }
                try (var generatedKeys = autoGeneratedPrimaryKey
                        ? query.getGeneratedKeys(model.primaryKeyType())
                        : batch.stream().map(Entity::id)) {
                    callback.process(generatedKeys);
                }
            });
        }
    }

    /**
     * Inserts a stream of entities into the database with the insertion process divided into batches of the specified size,
     * and returns a stream of the inserted entities.
     *
     * This method provides an efficient way to insert a large number of entities by batching them according to the specified
     * batch size. It fetches the inserted entities immediately after insertion to ensure that the returned entities reflect
     * any database-generated values or defaults. This is particularly useful when database triggers or default values are
     * involved.
     *
     * @param entities a stream of entities to insert. Each entity must not be null and must conform to the model constraints.
     * @param batchSize the size of the batches to use for the insertion operation. A larger batch size can improve performance
     *                  but may also increase the load on the database.
     * @return a stream of the inserted entities as they are stored in the database.
     * @throws PersistenceException if there is an error during the insertion or retrieval operation, such as a violation of
     *         database constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void insertAndFetch(@Nonnull Stream<E> entities, int batchSize, @Nonnull BatchCallback<E> callback) {
        insertAndFetchIds(entities, batchSize, ids -> callback.process(select(ids)));
    }

    /**
     * Updates a stream of entities in the database using the default batch size.
     *
     * This method updates entities provided in a stream, optimizing the update process by batching them
     * with a default size. This helps to reduce the number of database operations and can significantly improve
     * performance when updating large numbers of entities.
     *
     * @param entities a stream of entities to update. Each entity must not be null, must already exist in the database,
     *                 and must conform to the model constraints.
     * @throws PersistenceException if there is an error during the update operation, such as a violation of database constraints,
     *         connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void update(@Nonnull Stream<E> entities) {
        update(entities, defaultBatchSize);
    }

    /**
     * Updates a stream of entities in the database, with the update process divided into batches of the specified size.
     *
     * This method updates entities provided in a stream and uses the specified batch size for the update operation.
     * Batching the updates can greatly enhance performance by minimizing the number of database interactions, especially
     * useful when dealing with large volumes of data.
     *
     * @param entities a stream of entities to update. Each entity must not be null, must already exist in the database,
     *                 and must conform to the model constraints.
     * @param batchSize the size of the batches to use for the update operation. A larger batch size can improve performance
     *                  but may also increase the load on the database.
     * @throws PersistenceException if there is an error during the update operation, such as a violation of database constraints,
     *         connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void update(@Nonnull Stream<E> entities, int batchSize) {
        try (var query = prepareUpdateQuery()) {
            slice(entities, batchSize).forEach(batch -> {
                updateAndFetch(batch, () -> query, null);
            });
        }
    }

    /**
     * Updates a stream of entities in the database using the default batch size and returns a stream of the updated entities.
     *
     * This method updates entities provided in a stream, optimizing the update process by batching them with the default size.
     * It fetches the updated entities immediately after updating to ensure that the returned entities reflect any database-generated
     * values or defaults. This is particularly useful when database triggers or default values are involved.
     *
     * @param entities a stream of entities to update. Each entity must not be null, must already exist in the database,
     *                 and must conform to the model constraints.
     * @return a stream of the updated entities as they are stored in the database.
     * @throws PersistenceException if there is an error during the update or retrieval operation, such as a violation of
     *         database constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void updateAndFetch(@Nonnull Stream<E> entities, @Nonnull BatchCallback<E> callback) {
        updateAndFetch(entities, defaultBatchSize, callback);
    }

    /**
     * Updates a stream of entities in the database, with the update process divided into batches of the specified size,
     * and returns a stream of the updated entities.
     *
     * This method updates entities provided in a stream and uses the specified batch size for the update operation.
     * Batching the updates can greatly enhance performance by minimizing the number of database interactions, especially
     * useful when dealing with large volumes of data. It fetches the updated entities immediately after updating to ensure
     * that the returned entities reflect any database-generated values or defaults.
     *
     * @param entities a stream of entities to update. Each entity must not be null, must already exist in the database,
     *                 and must conform to the model constraints.
     * @param batchSize the size of the batches to use for the update operation. A larger batch size can improve performance
     *                  but may also increase the load on the database.
     * @return a stream of the updated entities as they are stored in the database.
     * @throws PersistenceException if there is an error during the update or retrieval operation, such as a violation of
     *         database constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void updateAndFetch(@Nonnull Stream<E> entities, int batchSize, @Nonnull BatchCallback<E> callback) {
        try (var query = prepareUpdateQuery()) {
            slice(entities, batchSize).forEach(batch -> updateAndFetch(batch, () -> query, callback));
        }
    }

    protected PreparedQuery prepareUpdateQuery() {
        var bindVars = orm.createBindVars();
        return orm.query(RAW."""
                UPDATE \{model.type()}
                SET \{bindVars}
                WHERE \{bindVars}""").prepare();
    }

    protected void updateAndFetchIds(@Nonnull List<E> batch, @Nonnull Supplier<PreparedQuery> querySupplier, @Nullable BatchCallback<ID> callback) {
        if (!batch.isEmpty()) {
            var query = querySupplier.get();
            batch.stream().map(Record.class::cast).forEach(query::addBatch);
            int[] result = query.executeBatch();
            if (query.isVersionAware() && IntStream.of(result).anyMatch(r -> r == 0)) {
                throw new OptimisticLockException("Update failed due to optimistic lock.");
            } else if (IntStream.of(result).anyMatch(r -> r != 1)) {
                throw new PersistenceException("Batch update failed.");
            }
        }
        if (callback != null) {
            callback.process(batch.stream().map(Entity::id));
        }
    }

    protected void updateAndFetch(@Nonnull List<E> batch, @Nonnull Supplier<PreparedQuery> query, @Nullable BatchCallback<E> callback) {
        updateAndFetchIds(batch, query, callback == null ? null : ids -> {
            try (var stream = select(ids)) {
                callback.process(stream);
            }
        });
    }

    /**
     * Performs an upsert operation for multiple entities provided as a stream. This method processes the entities with
     * the maximum batch size, optimizing the operation for large datasets by reducing the load on the database.
     *
     * @param entities a stream of entities to upsert. Each entity must not be null and must conform to the model
     *                constraints.
     * @throws PersistenceException if there is an error during the upsert operation, such as a violation of database
     *                              constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void upsert(@Nonnull Stream<E> entities) {
        throw upsertNotAvailable();
    }

    /**
     * Performs an upsert operation for multiple entities provided as a stream, with the operation divided into batches
     * of the specified size. This method is optimized for handling large datasets efficiently by reducing the number
     * of database transactions and spreading the load over multiple batches.
     *
     * Each entity in the stream is either inserted or updated based on whether it already exists in the database, as
     * determined by its primary key or unique constraints. This upsert operation is facilitated by a database-specific
     * command that handles duplicate keys by updating existing records.
     *
     * @param entities a stream of entities to upsert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @param batchSize the size of the batches to use for the upsert operation. A larger batch size can improve
     *                  performance but may also increase the load on the database.
     * @throws PersistenceException if there is an error during the upsert operation, such as a violation of database
     *                              constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void upsert(@Nonnull Stream<E> entities, int batchSize) {
        throw upsertNotAvailable();
    }

    /**
     * Performs an upsert operation for multiple entities provided as a stream and returns a stream of their generated
     * primary keys. This method uses the maximum batch size to process the entities efficiently, suitable for handling
     * large datasets.
     *
     * @param entities a stream of entities to upsert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @return a stream of primary keys for the upserted entities.
     * @throws PersistenceException if there is an error during the upsert or key retrieval operation, such as a
     *                              violation of database constraints, connectivity issues, or if any entity in the
     *                              stream is null.
     */
    @Override
    public void upsertAndFetchIds(@Nonnull Stream<E> entities, @Nonnull BatchCallback<ID> callback) {
        throw upsertNotAvailable();
    }

    /**
     * Performs an upsert operation for multiple entities provided as a stream and returns a stream of the entities as
     * stored in the database. This method uses the maximum batch size to optimize the database interaction, suitable
     * for handling large volumes of entities.
     *
     * @param entities a stream of entities to upsert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @return a stream of the upserted entities, reflecting their current state in the database.
     * @throws PersistenceException if there is an error during the upsert or retrieval operation, such as a violation
     *                              of database constraints, connectivity issues, or if any entity in the stream is
     *                              null.
     */
    @Override
    public void upsertAndFetch(@Nonnull Stream<E> entities, @Nonnull BatchCallback<E> callback) {
        throw upsertNotAvailable();
    }

    /**
     * Performs an upsert operation for multiple entities provided as a stream, with the operation divided into batches
     * of the specified size, and returns a stream of their generated primary keys. This method is optimized for
     * efficiently handling large datasets by reducing the load on the database and enhancing performance through
     * batching.
     *
     * @param entities a stream of entities to upsert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @param batchSize the size of the batches to use for the upsert operation. A larger batch size can improve
     *                  performance but may also increase the load on the database.
     * @return a stream of primary keys for the upserted entities.
     * @throws PersistenceException if there is an error during the upsert or key retrieval operation, such as a
     *                              violation of database constraints, connectivity issues, or if any entity in the
     *                              stream is null.
     */
    @Override
    public void upsertAndFetchIds(@Nonnull Stream<E> entities, int batchSize, @Nonnull BatchCallback<ID> callback) {
        throw upsertNotAvailable();
    }

    /**
     * Performs an upsert operation for multiple entities provided as a stream, with the operation divided into batches
     * of the specified size, and returns a stream of the entities as stored in the database after the upsert. This
     * method is designed to optimize large-scale upsert operations by efficiently handling large datasets through batch
     * processing.
     *
     * The method first upserts the entities and retrieves their primary keys. It then fetches the entities from the
     * database to ensure that the returned stream reflects their current state, including any database-generated values
     * or modifications resulting from the upsert operation.
     *
     * @param entities a stream of entities to upsert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @param batchSize the size of the batches to use for the upsert operation. Using a larger batch size can improve
     *                  performance by reducing the number of database interactions but may also increase the load on
     *                  the database.
     * @return a stream of the upserted entities, reflecting their current state in the database.
     * @throws PersistenceException if there is an error during the upsert or retrieval operation, such as a violation
     *                              of database constraints, connectivity issues, or if any entity in the stream is
     *                              null.
     */
    @Override
    public void upsertAndFetch(@Nonnull Stream<E> entities, int batchSize, @Nonnull BatchCallback<E> callback) {
        throw upsertNotAvailable();
    }

    /**
     * Deletes a stream of entities from the database using the default batch size.
     *
     * This method deletes entities provided in a stream, optimizing the deletion process by batching them
     * with the default size. This helps to reduce the number of database operations and can significantly improve
     * performance when deleting large numbers of entities.
     *
     * @param entities a stream of entities to delete. Each entity must not be null, must already exist in the database,
     *                 and must conform to the model constraints.
     * @throws PersistenceException if there is an error during the deletion operation, such as a violation of database constraints,
     *         connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void delete(@Nonnull Stream<E> entities) {
        delete(entities, defaultBatchSize);
    }

    /**
     * Deletes a stream of entities from the database, with the deletion process divided into batches of the specified size.
     *
     * This method deletes entities provided in a stream and uses the specified batch size for the deletion operation.
     * Batching the deletions can greatly enhance performance by minimizing the number of database interactions, especially
     * useful when dealing with large volumes of data.
     *
     * @param entities a stream of entities to delete. Each entity must not be null, must already exist in the database,
     *                 and must conform to the model constraints.
     * @param batchSize the size of the batches to use for the deletion operation. A larger batch size can improve performance
     *                  but may also increase the load on the database.
     * @throws PersistenceException if there is an error during the deletion operation, such as a violation of database constraints,
     *         connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void delete(@Nonnull Stream<E> entities, int batchSize) {
        var bindVars = orm.createBindVars();
        try (var query = orm.query(RAW."""
                DELETE FROM \{model.type()}
                WHERE \{bindVars}""").prepare()) {
            slice(entities, batchSize).forEach(slice -> {
                slice.stream().map(Record.class::cast).forEach(query::addBatch);
                int[] result = query.executeBatch();
                if (IntStream.of(result).anyMatch(r -> r != 1)) {
                    throw new PersistenceException("Batch delete failed.");
                }
            });
        }
    }

    /**
     * Returns the single result of the stream.
     *
     * @param stream the stream to get the single result from.
     * @return the single result of the stream.
     * @param <T> the type of the result.
     * @throws NoResultException if there is no result.
     * @throws NonUniqueResultException if more than one result.
     */
    private <T> T singleResult(Stream<T> stream) {
        try (stream) {
            return stream
                    .reduce((_, _) -> {
                        throw new NonUniqueResultException("Expected single result, but found more than one.");
                    }).orElseThrow(() -> new NoResultException("Expected single result, but found none."));
        }
    }
}
