/*
 * Copyright 2024 the original author or authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package st.orm.spi.mysql;

import jakarta.annotation.Nonnull;
import jakarta.annotation.Nullable;
import jakarta.persistence.PersistenceException;
import st.orm.PreparedQuery;
import st.orm.repository.Column;
import st.orm.repository.Entity;
import st.orm.repository.EntityModel;
import st.orm.BatchCallback;
import st.orm.spi.EntityRepositoryImpl;
import st.orm.template.ORMRepositoryTemplate;
import st.orm.template.impl.LazySupplier;

import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.function.Supplier;
import java.util.stream.IntStream;
import java.util.stream.Stream;

import static java.lang.StringTemplate.RAW;
import static java.util.stream.Collectors.partitioningBy;
import static java.util.stream.Stream.empty;
import static st.orm.Templates.unsafe;
import static st.orm.template.QueryBuilder.slice;

/**
 * Implementation of {@link st.orm.repository.EntityRepository} for MySQL.
 */
public class MysqlEntityRepositoryImpl<E extends Record & Entity<ID>, ID> extends EntityRepositoryImpl<E, ID> {

    public MysqlEntityRepositoryImpl(@Nonnull ORMRepositoryTemplate orm, @Nonnull EntityModel<E, ID> model) {
        super(orm, model);
    }

    private String onDuplicateKey() {
        var values = new ArrayList<String>();
        // LAST_INSERT_ID() is used to get the last auto-generated primary key value in case no fields are updated.
        model.columns().stream()
                .filter(Column::primaryKey)
                .map(column -> {
                    if (column.autoGenerated()) {
                        return STR."\{column.columnName()} = LAST_INSERT_ID(\{column.columnName()})";
                    } else {
                        return STR."\{column.columnName()} = VALUES(\{column.columnName()})";
                    }
                })
                .forEach(values::add);
        model.columns().stream()
                .filter(column -> !column.primaryKey())
                .filter(Column::updatable)
                .map(column -> STR."\{column.columnName()} = VALUES(\{column.columnName()})")
                .forEach(values::add);
        if (values.isEmpty()) {
            return "";
        }
        return STR."\nON DUPLICATE KEY UPDATE \{String.join(", ", values)}";
    }

    /**
     * Performs an upsert operation for a single entity into the database. If the entity already exists
     * (as determined by its primary key or unique constraints), it is updated; otherwise, a new entity is inserted.
     *
     * This method handles duplicates by executing a database-specific upsert operation, which may involve SQL
     * extensions or functions depending on the underlying database implementation.
     *
     * @param entity the entity to insert or update. Must not be null and must conform to the model constraints.
     * @throws PersistenceException if there is an error during the upsert operation, such as a violation of database
     *                              constraints, connectivity issues, or if the entity is null.
     */
    @Override
    public void upsert(@Nonnull E entity) {
        if (!isUpsert(entity)) {
            update(entity);
            return;
        }
        var query = orm.query(RAW."""
                INSERT INTO \{model.type()}
                VALUES \{entity}\{unsafe(onDuplicateKey())}""");
        query.executeUpdate();
    }

    /**
     * Performs an upsert operation for a single entity and fetches the primary key of the inserted or updated entity.
     * This is typically used when the primary keys are generated by the database (e.g., auto-increment IDs).
     *
     * The operation ensures that if an entity with a matching key exists, it is updated; otherwise, a new entity is
     * inserted. The primary key of the entity is then retrieved.
     *
     * @param entity the entity to insert or update. Must not be null and must conform to the model constraints.
     * @return the primary key of the upserted entity.
     * @throws PersistenceException if there is an error during the upsert or key retrieval operation, such as a
     *                              violation of database constraints, connectivity issues, or if the entity is null.
     */
    @Override
    public ID upsertAndFetchId(@Nonnull E entity) {
        if (!isUpsert(entity)) {
            update(entity);
            return entity.id();
        }
        try (var query = orm.query(RAW."""
                INSERT INTO \{model.type()}
                VALUES \{entity}\{unsafe(onDuplicateKey())}""").prepare()) {
            query.executeUpdate();
            return singleResult(query.getGeneratedKeys(model.primaryKeyType()));
        }
    }

    /**
     * Performs an upsert operation for a single entity and fetches the entity as stored in the database after the
     * operation. This method is useful to obtain the complete entity including any fields that may be generated or
     * modified by the database.
     *
     * @param entity the entity to insert or update. Must not be null and must conform to the model constraints.
     * @return the upserted entity, as retrieved from the database.
     * @throws PersistenceException if there is an error during the upsert or retrieval operation, such as a violation
     *                              of database constraints, connectivity issues, or if the entity is null.
     */
    @Override
    public E upsertAndFetch(@Nonnull E entity) {
        return select(upsertAndFetchId(entity));
    }

    /**
     * Performs an upsert operation for multiple entities provided as an iterable in a single batch.
     *
     * @param entities an iterable of entities to upsert. Each entity must not be null and must conform to the model
     *                constraints.
     * @throws PersistenceException if there is an error during the upsert operation, such as a violation of database
     *                              constraints, connectivity issues, or if any entity in the iterable is null.
     */
    @Override
    public void upsert(@Nonnull Iterable<E> entities) {
        upsert(toStream(entities), defaultBatchSize);
    }

    /**
     * Performs an upsert operation for multiple entities in a single batch and fetches their primary keys.
     *
     * @param entities an iterable of entities to upsert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @return a list of primary keys of the upserted entities.
     * @throws PersistenceException if there is an error during the upsert or key retrieval operation, such as a
     *                              violation of database constraints, connectivity issues, or if any entity in the
     *                              iterable is null.
     */
    @Override
    public List<ID> upsertAndFetchIds(@Nonnull Iterable<E> entities) {
        LazySupplier<PreparedQuery> upsertQuery = new LazySupplier<>(this::prepareUpsertQuery);
        LazySupplier<PreparedQuery> updateQuery = new LazySupplier<>(this::prepareUpdateQuery);
        try {
            return slice(toStream(entities), defaultBatchSize, batch -> {
                var result = new ArrayList<ID>();
                var partition = partition(batch);
                updateAndFetchIds(partition.get(false), updateQuery, ids -> result.addAll(ids.toList()));
                upsertAndFetchIds(partition.get(true), upsertQuery, ids -> result.addAll(ids.toList()));
                return result.stream();
            }).toList();
        } finally {
            try {
                upsertQuery.value().ifPresent(PreparedQuery::close);
            } finally {
                updateQuery.value().ifPresent(PreparedQuery::close);
            }
        }
    }

    /**
     * Performs an upsert operation for multiple entities in a single batch and fetches the entities as stored in
     * the database after the upsert.
     *
     * @param entities an iterable of entities to upsert. Each entity must not be null and must conform to the model
     *                constraints.
     * @return a list of the upserted entities, as retrieved from the database.
     * @throws PersistenceException if there is an error during the upsert or retrieval operation, such as a violation
     *                              of database constraints, connectivity issues, or if any entity in the iterable is
     *                              null.
     */
    @Override
    public List<E> upsertAndFetch(@Nonnull Iterable<E> entities) {
        return select(upsertAndFetchIds(entities));
    }

    /**
     * Performs an upsert operation for multiple entities provided as a stream. This method processes the entities with
     * the maximum batch size, optimizing the operation for large datasets by reducing the load on the database.
     *
     * @param entities a stream of entities to upsert. Each entity must not be null and must conform to the model
     *                constraints.
     * @throws PersistenceException if there is an error during the upsert operation, such as a violation of database
     *                              constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void upsert(@Nonnull Stream<E> entities) {
        upsert(entities, defaultBatchSize);
    }

    /**
     * Performs an upsert operation for multiple entities provided as a stream, with the operation divided into batches
     * of the specified size. This method is optimized for handling large datasets efficiently by reducing the number
     * of database transactions and spreading the load over multiple batches.
     *
     * Each entity in the stream is either inserted or updated based on whether it already exists in the database, as
     * determined by its primary key or unique constraints. This upsert operation is facilitated by a database-specific
     * command that handles duplicate keys by updating existing records.
     *
     * @param entities a stream of entities to upsert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @param batchSize the size of the batches to use for the upsert operation. A larger batch size can improve
     *                  performance but may also increase the load on the database.
     * @throws PersistenceException if there is an error during the upsert operation, such as a violation of database
     *                              constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void upsert(@Nonnull Stream<E> entities, int batchSize) {
        LazySupplier<PreparedQuery> upsertQuery = new LazySupplier<>(this::prepareUpsertQuery);
        LazySupplier<PreparedQuery> updateQuery = new LazySupplier<>(this::prepareUpdateQuery);
        try {
            slice(entities, batchSize).forEach(batch -> {
                var partition = partition(batch);
                updateAndFetch(partition.get(false), updateQuery, null);
                upsertAndFetch(partition.get(true), upsertQuery, null);
            });
        } finally {
            try {
                upsertQuery.value().ifPresent(PreparedQuery::close);
            } finally {
                updateQuery.value().ifPresent(PreparedQuery::close);
            }
        }
    }

    /**
     * Performs an upsert operation for multiple entities provided as a stream and returns a stream of their generated
     * primary keys. This method uses the maximum batch size to process the entities efficiently, suitable for handling
     * large datasets.
     *
     * @param entities a stream of entities to upsert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @return a stream of primary keys for the upserted entities.
     * @throws PersistenceException if there is an error during the upsert or key retrieval operation, such as a
     *                              violation of database constraints, connectivity issues, or if any entity in the
     *                              stream is null.
     */
    @Override
    public void upsertAndFetchIds(@Nonnull Stream<E> entities, @Nonnull BatchCallback<ID> callback) {
        upsertAndFetchIds(entities, defaultBatchSize, callback);
    }

    /**
     * Performs an upsert operation for multiple entities provided as a stream and returns a stream of the entities as
     * stored in the database. This method uses the maximum batch size to optimize the database interaction, suitable
     * for handling large volumes of entities.
     *
     * @param entities a stream of entities to upsert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @return a stream of the upserted entities, reflecting their current state in the database.
     * @throws PersistenceException if there is an error during the upsert or retrieval operation, such as a violation
     *                              of database constraints, connectivity issues, or if any entity in the stream is
     *                              null.
     */
    @Override
    public void upsertAndFetch(@Nonnull Stream<E> entities, @Nonnull BatchCallback<E> callback) {
        upsertAndFetch(entities, defaultBatchSize, callback);
    }

    /**
     * Performs an upsert operation for multiple entities provided as a stream, with the operation divided into batches
     * of the specified size, and returns a stream of their generated primary keys. This method is optimized for
     * efficiently handling large datasets by reducing the load on the database and enhancing performance through
     * batching.
     *
     * @param entities a stream of entities to upsert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @param batchSize the size of the batches to use for the upsert operation. A larger batch size can improve
     *                  performance but may also increase the load on the database.
     * @return a stream of primary keys for the upserted entities.
     * @throws PersistenceException if there is an error during the upsert or key retrieval operation, such as a
     *                              violation of database constraints, connectivity issues, or if any entity in the
     *                              stream is null.
     */
    @Override
    public void upsertAndFetchIds(@Nonnull Stream<E> entities, int batchSize, @Nonnull BatchCallback<ID> callback) {
        LazySupplier<PreparedQuery> upsertQuery = new LazySupplier<>(this::prepareUpsertQuery);
        LazySupplier<PreparedQuery> updateQuery = new LazySupplier<>(this::prepareUpdateQuery);
        try {
            slice(entities, batchSize).forEach(batch -> {
                var partition = partition(batch);
                updateAndFetchIds(partition.get(false), updateQuery, callback);
                upsertAndFetchIds(partition.get(true), upsertQuery, callback);
            });
        } finally {
            try {
                upsertQuery.value().ifPresent(PreparedQuery::close);
            } finally {
                updateQuery.value().ifPresent(PreparedQuery::close);
            }
        }
    }

    /**
     * Performs an upsert operation for multiple entities provided as a stream, with the operation divided into batches
     * of the specified size, and returns a stream of the entities as stored in the database after the upsert. This
     * method is designed to optimize large-scale upsert operations by efficiently handling large datasets through batch
     * processing.
     *
     * The method first upserts the entities and retrieves their primary keys. It then fetches the entities from the
     * database to ensure that the returned stream reflects their current state, including any database-generated values
     * or modifications resulting from the upsert operation.
     *
     * @param entities a stream of entities to upsert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @param batchSize the size of the batches to use for the upsert operation. Using a larger batch size can improve
     *                  performance by reducing the number of database interactions but may also increase the load on
     *                  the database.
     * @return a stream of the upserted entities, reflecting their current state in the database.
     * @throws PersistenceException if there is an error during the upsert or retrieval operation, such as a violation
     *                              of database constraints, connectivity issues, or if any entity in the stream is
     *                              null.
     */
    @Override
    public void upsertAndFetch(@Nonnull Stream<E> entities, int batchSize, @Nonnull BatchCallback<E> callback) {
        LazySupplier<PreparedQuery> upsertQuery = new LazySupplier<>(this::prepareUpsertQuery);
        LazySupplier<PreparedQuery> updateQuery = new LazySupplier<>(this::prepareUpdateQuery);
        try {
            slice(entities, batchSize).forEach(batch -> {
                var partition = partition(batch);
                updateAndFetch(partition.get(false), updateQuery, callback);
                upsertAndFetch(partition.get(true), upsertQuery, callback);
            });
        } finally {
            try {
                upsertQuery.value().ifPresent(PreparedQuery::close);
            } finally {
                updateQuery.value().ifPresent(PreparedQuery::close);
            }
        }
    }

    private boolean isUpsert(@Nonnull E entity) {
        if (autoGeneratedPrimaryKey) {
            return isDefault(entity);
        }
        return true;
    }

    private Map<Boolean, List<E>> partition(@Nonnull List<E> entities) {
        return entities.stream().collect(partitioningBy(this::isUpsert));
    }

    protected PreparedQuery prepareUpsertQuery() {
        var bindVars = orm.createBindVars();
        return orm.query(RAW."""
                INSERT INTO \{model.type()}
                VALUES \{bindVars}\{unsafe(onDuplicateKey())}""").prepare();
    }

    protected void upsertAndFetchIds(@Nonnull List<E> batch, @Nonnull Supplier<PreparedQuery> querySupplier, @Nullable BatchCallback<ID> callback) {
        if (batch.isEmpty()) {
            if (callback != null) {
                callback.process(empty());
            }
            return;
        }
        var query = querySupplier.get();
        batch.stream().map(Record.class::cast).forEach(query::addBatch);
        int[] result = query.executeBatch();
        if (IntStream.of(result).anyMatch(r -> r != 1 && r != 2)) {
            throw new PersistenceException("Batch upsert failed.");
        }
        if (callback != null) {
            try (var generatedKeys = query.getGeneratedKeys(model.primaryKeyType())) {
                callback.process(generatedKeys);
            }
        }
    }

    protected void upsertAndFetch(@Nonnull List<E> batch, @Nonnull Supplier<PreparedQuery> querySupplier, @Nullable BatchCallback<E> callback) {
        upsertAndFetchIds(batch, querySupplier, callback == null ? null : ids -> {
            try (var stream = select(ids)) {
                callback.process(stream);
            }
        });
    }
}
