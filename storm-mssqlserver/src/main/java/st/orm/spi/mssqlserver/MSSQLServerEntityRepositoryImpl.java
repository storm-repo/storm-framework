/*
 * Copyright 2024 - 2025 the original author or authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package st.orm.spi.mssqlserver;

import jakarta.annotation.Nonnull;
import jakarta.annotation.Nullable;
import st.orm.core.BatchCallback;
import st.orm.core.EntityRepository;
import st.orm.core.PreparedQuery;
import st.orm.core.spi.EntityRepositoryImpl;
import st.orm.core.template.Column;
import st.orm.core.template.Model;
import st.orm.core.template.ORMTemplate;
import st.orm.core.template.TemplateString;
import st.orm.core.template.impl.LazySupplier;
import st.orm.BindVars;
import st.orm.Entity;
import st.orm.PersistenceException;

import java.lang.StringTemplate;
import java.math.BigInteger;
import java.sql.Timestamp;
import java.time.Instant;
import java.util.ArrayList;
import java.util.Calendar;
import java.util.Date;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicReference;
import java.util.function.Supplier;
import java.util.stream.IntStream;
import java.util.stream.Stream;

import static java.util.function.Predicate.not;
import static java.util.stream.Collectors.joining;
import static java.util.stream.Collectors.partitioningBy;
import static java.util.stream.Stream.empty;
import static st.orm.core.Templates.bindVar;
import static st.orm.core.template.QueryBuilder.slice;
import static st.orm.core.template.SqlInterceptor.intercept;
import static st.orm.core.template.TemplateString.combine;
import static st.orm.core.template.TemplateString.wrap;
import static st.orm.core.template.impl.StringTemplates.flatten;

/**
 * Implementation of {@link EntityRepository} for SQL Server.
 */
public class MSSQLServerEntityRepositoryImpl<E extends Record & Entity<ID>, ID>
        extends EntityRepositoryImpl<E, ID> {

    public MSSQLServerEntityRepositoryImpl(@Nonnull ORMTemplate ormTemplate, @Nonnull Model<E, ID> model) {
        super(ormTemplate, model);
    }

    /**
     * Constructs a version update string for a version column. For numeric types the column is incremented,
     * for date/timestamp types CURRENT_TIMESTAMP is used.
     */
    private String getVersionString(@Nonnull Column column) {
        String columnName = column.qualifiedName(ormTemplate.dialect());
        String updateExpression = switch (column.type()) {
            case Class<?> c when Integer.TYPE.isAssignableFrom(c)
                    || Long.TYPE.isAssignableFrom(c)
                    || Integer.class.isAssignableFrom(c)
                    || Long.class.isAssignableFrom(c)
                    || BigInteger.class.isAssignableFrom(c) -> "t.%s + 1".formatted(columnName);
            case Class<?> c when Instant.class.isAssignableFrom(c)
                    || Date.class.isAssignableFrom(c)
                    || Calendar.class.isAssignableFrom(c)
                    || Timestamp.class.isAssignableFrom(c) -> "CURRENT_TIMESTAMP";
            default ->
                    throw new PersistenceException(STR."Unsupported version type: \{column.type().getSimpleName()}.");
        };
        return STR."t.\{columnName} = \{updateExpression}";
    }

    /**
     * Builds a SELECT clause for the merge source based on the entity’s current values.
     * (Note: Unlike Oracle, SQL Server does not require a FROM DUAL clause.)
     */
    private TemplateString mergeSelect(@Nonnull E entity) {
        var dialect = ormTemplate.dialect();
        var values = model.getValues(entity);
        var duplicates = new HashSet<>(); // Ensure each column appears only once.
        return values.entrySet().stream()
                .filter(entry -> duplicates.add(entry.getKey().name()))
                .map(entry -> {
                    Column column = entry.getKey();
                    Object value = entry.getValue();
                    if (column.primaryKey() && column.autoGenerated()) {
                        //noinspection unchecked
                        if (model.isDefaultPrimaryKey((ID) value)) {
                            value = null;
                        }
                    }
                    return combine(wrap(value), TemplateString.raw(" AS %s".formatted(column.qualifiedName(dialect))));
                })
                .reduce((left, right) -> combine(left, TemplateString.raw(", "), right))
                .map(t -> combine(TemplateString.raw("SELECT "), t))
                .orElseThrow();
    }

    /**
     * Builds a SELECT clause for the merge source based on bind variables.
     */
    private TemplateString mergeSelect(@Nonnull BindVars bindVars) {
        var values = new AtomicReference<Map<Column, ?>>();
        //noinspection unchecked
        bindVars.setRecordListener(record -> values.setPlain(model.getValues((E) record)));
        var duplicates = new HashSet<>();
        return model.columns().stream()
                .filter(column -> duplicates.add(column.name()))
                .map(c -> combine(wrap(bindVar(bindVars, _ -> values.getPlain().get(c))),
                        TemplateString.raw(" AS %s".formatted(c.name()))))
                .reduce((left, right) -> combine(left, TemplateString.raw(", "), right))
                .map(t -> combine(TemplateString.raw("SELECT "), t))
                .orElseThrow();
    }

    /**
     * Constructs the ON clause by equating primary key columns.
     */
    private TemplateString mergeOn() {
        var dialect = ormTemplate.dialect();
        var primaryKeys = model.columns().stream()
                .filter(Column::primaryKey)
                .toList();
        String sql = primaryKeys.stream()
                .map(c -> "t.%s = src.%s".formatted(c.qualifiedName(dialect), c.qualifiedName(dialect)))
                .collect(joining(" AND "));
        return TemplateString.raw(sql);
    }

    /**
     * Constructs the UPDATE clause for the MERGE statement.
     */
    private StringTemplate mergeUpdate(@Nonnull AtomicBoolean versionAware) {
        var dialect = ormTemplate.dialect();
        var duplicates = new HashSet<>();
        var args = model.columns().stream()
                .filter(not(Column::primaryKey))
                .filter(Column::updatable)
                .filter(column -> duplicates.add(column.name()))
                .map(column -> {
                    if (column.version()) {
                        versionAware.setPlain(true);
                        return getVersionString(column);
                    }
                    return "t.%s = src.%s".formatted(column.qualifiedName(dialect), column.qualifiedName(dialect));
                })
                .toList();
        if (args.isEmpty()) {
            return StringTemplate.of("");
        }
        String sql = args.stream().collect(joining(", ", "UPDATE SET ", ""));
        return StringTemplate.of("\nWHEN MATCHED THEN\n\t%s".formatted(sql));
    }

    /**
     * Constructs the INSERT clause for the MERGE statement.
     */
    private StringTemplate mergeInsert() {
        var dialect = ormTemplate.dialect();
        var insertDuplicates = new HashSet<>();
        var insertArgs = model.columns().stream()
                .filter(c -> !c.primaryKey() || !c.autoGenerated())
                .map(Column::name)
                .filter(insertDuplicates::add)
                .toList();
        var valuesDuplicates = new HashSet<>();
        var valuesArgs = model.columns().stream()
                .filter(c -> !c.primaryKey() || !c.autoGenerated())
                .filter(column -> valuesDuplicates.add(column.name()))
                .map(c -> STR."src.\{c.qualifiedName(dialect)}")
                .toList();
        if (insertArgs.isEmpty()) {
            return StringTemplate.of("");
        }
        String insertSql = String.join(", ", insertArgs);
        String valuesSql = String.join(", ", valuesArgs);
        String sql = STR."\n\tINSERT (\{insertSql})\n\tVALUES (\{valuesSql})";
        return StringTemplate.of(STR."\nWHEN NOT MATCHED THEN\{sql}");
    }

    /**
     * Validates the entity for an upsert operation.
     */
    protected E validateUpsert(@Nonnull E entity) {
        if (autoGeneratedPrimaryKey && !model.isDefaultPrimaryKey(entity.id())) {
            throw new PersistenceException("Primary key must not be set for auto-generated primary keys for upserts.");
        }
        return entity;
    }

    /**
     * Inserts or updates a single entity in the database.
     */
    @Override
    public void upsert(@Nonnull E entity) {
        if (isUpdate(entity)) {
            update(entity);
            return;
        }
        if (autoGeneratedPrimaryKey) {
            // In auto-generated mode, an insert is performed.
            insert(entity);
            return;
        }
        validateUpsert(entity);
        var versionAware = new AtomicBoolean();
        intercept(sql -> sql.versionAware(versionAware.getPlain()), () -> {
            // Note: SQL Server’s MERGE syntax does not require a FROM DUAL clause.
            var query = ormTemplate.query(flatten(TemplateString.raw("""
                MERGE INTO \0 t
                USING (\0) src
                ON (\0)\0\0""", model.type(), mergeSelect(entity), mergeOn(), mergeUpdate(versionAware), mergeInsert())));
                query.executeUpdate();
        });
    }

    /**
     * Inserts or updates a single entity and returns its ID.
     */
    @Override
    public ID upsertAndFetchId(@Nonnull E entity) {
        if (isUpdate(entity)) {
            update(entity);
            return entity.id();
        }
        if (autoGeneratedPrimaryKey) {
            return insertAndFetchId(entity);
        }
        validateUpsert(entity);
        upsert(entity);
        return entity.id();
    }

    /**
     * Inserts or updates a single entity and returns the entity’s current state.
     */
    @Override
    public E upsertAndFetch(@Nonnull E entity) {
        return getById(upsertAndFetchId(entity));
    }

    /**
     * Batch upsert for an iterable of entities.
     */
    @Override
    public void upsert(@Nonnull Iterable<E> entities) {
        upsert(toStream(entities), defaultBatchSize);
    }

    /**
     * Batch upsert for an iterable of entities returning a list of IDs.
     */
    @Override
    public List<ID> upsertAndFetchIds(@Nonnull Iterable<E> entities) {
        LazySupplier<PreparedQuery> updateQuery = new LazySupplier<>(this::prepareUpdateQuery);
        LazySupplier<PreparedQuery> insertQuery = new LazySupplier<>(this::prepareInsertQuery);
        LazySupplier<PreparedQuery> upsertQuery = new LazySupplier<>(this::prepareUpsertQuery);
        try {
            return slice(toStream(entities), defaultBatchSize, batch -> {
                var result = new ArrayList<ID>();
                var partition = partition(batch);
                updateAndFetchIds(partition.get(true), updateQuery, ids -> result.addAll(ids.toList()));
                if (autoGeneratedPrimaryKey) {
                    insertAndFetchIds(partition.get(false), insertQuery, ids -> result.addAll(ids.toList()));
                } else {
                    upsertAndFetchIds(partition.get(false), upsertQuery, ids -> result.addAll(ids.toList()));
                }
                return result.stream();
            }).toList();
        } finally {
            closeQuietly(updateQuery, insertQuery, upsertQuery);
        }
    }

    /**
     * Batch upsert for an iterable of entities returning the updated entities.
     */
    @Override
    public List<E> upsertAndFetch(@Nonnull Iterable<E> entities) {
        return findAllById(upsertAndFetchIds(entities));
    }

    /**
     * Batch upsert for a stream of entities.
     */
    @Override
    public void upsert(@Nonnull Stream<E> entities) {
        upsert(entities, defaultBatchSize);
    }

    /**
     * Batch upsert for a stream of entities in configurable batch sizes.
     */
    @Override
    public void upsert(@Nonnull Stream<E> entities, int batchSize) {
        LazySupplier<PreparedQuery> updateQuery = new LazySupplier<>(this::prepareUpdateQuery);
        LazySupplier<PreparedQuery> insertQuery = new LazySupplier<>(this::prepareInsertQuery);
        LazySupplier<PreparedQuery> upsertQuery = new LazySupplier<>(this::prepareUpsertQuery);
        try {
            slice(entities, batchSize).forEach(batch -> {
                var partition = partition(batch);
                updateAndFetch(partition.get(true), updateQuery, null);
                if (autoGeneratedPrimaryKey) {
                    insertAndFetchIds(partition.get(false), insertQuery, null);
                } else {
                    upsertAndFetchIds(partition.get(false), upsertQuery, null);
                }
            });
        } finally {
            closeQuietly(updateQuery, insertQuery, upsertQuery);
        }
    }

    @Override
    public void upsertAndFetchIds(@Nonnull Stream<E> entities, @Nonnull BatchCallback<ID> callback) {
        upsertAndFetchIds(entities, defaultBatchSize, callback);
    }

    @Override
    public void upsertAndFetch(@Nonnull Stream<E> entities, @Nonnull BatchCallback<E> callback) {
        upsertAndFetch(entities, defaultBatchSize, callback);
    }

    @Override
    public void upsertAndFetchIds(@Nonnull Stream<E> entities, int batchSize, @Nonnull BatchCallback<ID> callback) {
        LazySupplier<PreparedQuery> updateQuery = new LazySupplier<>(this::prepareUpdateQuery);
        LazySupplier<PreparedQuery> insertQuery = new LazySupplier<>(this::prepareInsertQuery);
        LazySupplier<PreparedQuery> upsertQuery = new LazySupplier<>(this::prepareUpsertQuery);
        try {
            slice(entities, batchSize).forEach(batch -> {
                var partition = partition(batch);
                updateAndFetchIds(partition.get(true), updateQuery, callback);
                if (autoGeneratedPrimaryKey) {
                    insertAndFetchIds(partition.get(false), insertQuery, callback);
                } else {
                    upsertAndFetchIds(partition.get(false), upsertQuery, callback);
                }
            });
        } finally {
            closeQuietly(updateQuery, insertQuery, upsertQuery);
        }
    }

    @Override
    public void upsertAndFetch(@Nonnull Stream<E> entities, int batchSize, @Nonnull BatchCallback<E> callback) {
        LazySupplier<PreparedQuery> updateQuery = new LazySupplier<>(this::prepareUpdateQuery);
        LazySupplier<PreparedQuery> insertQuery = new LazySupplier<>(this::prepareInsertQuery);
        LazySupplier<PreparedQuery> upsertQuery = new LazySupplier<>(this::prepareUpsertQuery);
        try {
            slice(entities, batchSize).forEach(batch -> {
                var partition = partition(batch);
                updateAndFetch(partition.get(true), updateQuery, callback);
                if (autoGeneratedPrimaryKey) {
                    insertAndFetch(partition.get(false), insertQuery, callback);
                } else {
                    upsertAndFetch(partition.get(false), upsertQuery, callback);
                }
            });
        } finally {
            closeQuietly(updateQuery, insertQuery, upsertQuery);
        }
    }

    private boolean isUpdate(@Nonnull E entity) {
        return autoGeneratedPrimaryKey && !model.isDefaultPrimaryKey(entity.id());
    }

    private Map<Boolean, List<E>> partition(@Nonnull List<E> entities) {
        return entities.stream().collect(partitioningBy(this::isUpdate));
    }

    protected PreparedQuery prepareInsertQuery() {
        var bindVars = ormTemplate.createBindVars();
        return ormTemplate.query(TemplateString.raw("""
                INSERT INTO \0
                VALUES \0""", model.type(), bindVars)).prepare();
    }

    protected PreparedQuery prepareUpsertQuery() {
        var bindVars = ormTemplate.createBindVars();
        var versionAware = new AtomicBoolean();
        return intercept(sql -> sql.versionAware(versionAware.getPlain()), () ->
                ormTemplate.query(flatten(TemplateString.raw("""
                    MERGE INTO \0 t
                    USING (\0) src
                    ON (\0)\0\0""", model.type(), mergeSelect(bindVars), mergeOn(), mergeUpdate(versionAware), mergeInsert()))
                ).prepare());
    }

    protected void insertAndFetchIds(@Nonnull List<E> batch,
                                     @Nonnull Supplier<PreparedQuery> querySupplier,
                                     @Nullable BatchCallback<ID> callback) {
        if (batch.isEmpty()) {
            if (callback != null) {
                callback.process(empty());
            }
            return;
        }
        var query = querySupplier.get();
        batch.stream().map(this::validateInsert).map(Record.class::cast).forEach(query::addBatch);
        int[] result = query.executeBatch();
        if (IntStream.of(result).anyMatch(r -> r != 0 && r != 1 && r != 2)) {
            throw new PersistenceException("Batch insert failed.");
        }
        if (callback != null) {
            callback.process(batch.stream().map(Entity::id));
        }
    }

    protected void upsertAndFetchIds(@Nonnull List<E> batch,
                                     @Nonnull Supplier<PreparedQuery> querySupplier,
                                     @Nullable BatchCallback<ID> callback) {
        if (batch.isEmpty()) {
            if (callback != null) {
                callback.process(empty());
            }
            return;
        }
        var query = querySupplier.get();
        batch.stream().map(this::validateUpsert).map(Record.class::cast).forEach(query::addBatch);
        int[] result = query.executeBatch();
        if (IntStream.of(result).anyMatch(r -> r != 0 && r != 1 && r != 2)) {
            throw new PersistenceException("Batch upsert failed.");
        }
        if (callback != null) {
            callback.process(batch.stream().map(Entity::id));
        }
    }

    protected void insertAndFetch(@Nonnull List<E> batch,
                                  @Nonnull Supplier<PreparedQuery> querySupplier,
                                  @Nullable BatchCallback<E> callback) {
        insertAndFetchIds(batch, querySupplier, callback == null ? null : ids -> {
            try (var stream = selectById(ids)) {
                callback.process(stream);
            }
        });
    }

    protected void upsertAndFetch(@Nonnull List<E> batch,
                                  @Nonnull Supplier<PreparedQuery> querySupplier,
                                  @Nullable BatchCallback<E> callback) {
        upsertAndFetchIds(batch, querySupplier, callback == null ? null : ids -> {
            try (var stream = selectById(ids)) {
                callback.process(stream);
            }
        });
    }

    /**
     * Helper method to close lazy-supplied queries without one exception blocking another.
     */
    private void closeQuietly(LazySupplier<PreparedQuery> updateQuery,
                              LazySupplier<PreparedQuery> insertQuery,
                              LazySupplier<PreparedQuery> upsertQuery) {
        try {
            upsertQuery.value().ifPresent(PreparedQuery::close);
        } finally {
            try {
                insertQuery.value().ifPresent(PreparedQuery::close);
            } finally {
                updateQuery.value().ifPresent(PreparedQuery::close);
            }
        }
    }

    //
    // Override default logic as Sql Server does not support batch insert in combination with generated keys.
    //

    /**
     * Inserts a collection of entities into the database in batches.
     *
     * <p>This method processes the provided entities in batches, optimizing insertion for larger collections by
     * reducing database overhead. Batch processing helps ensure that even large numbers of entities can be
     * inserted efficiently and minimizes potential memory and performance issues.</p>
     *
     * <p>Upon successful insertion, it returns the primary keys assigned to the entities when the primary keys are
     * generated by the database (e.g., auto-incremented). Otherwise, if the primary keys are not generated by the
     * database, the method returns an empty list.</p>
     *
     * @param entities an iterable collection of entities to be inserted. Each entity in the collection must
     *                 be non-null and contain valid data for insertion.
     * @return the primary keys assigned to the entities when the primary keys are generated by the database,
     * @throws PersistenceException if the insertion operation fails due to database issues, such as connectivity
     *                              problems, constraints violations, or invalid entity data.
     */
    @Override
    public List<ID> insertAndFetchIds(@Nonnull Iterable<E> entities) {
        // Insert the entities one by one.
        return toStream(entities).map(this::insertAndFetchId).toList();
    }

    /**
     * Inserts a collection of entities into the database in batches.
     *
     * <p>This method processes the provided entities in batches, optimizing insertion for larger collections by
     * reducing database overhead. Batch processing helps ensure that even large numbers of entities can be
     * inserted efficiently and minimizes potential memory and performance issues.</p>
     *
     * <p>Upon successful insertion, it returns the entities that were inserted. The returned entities reflect the
     * state of the entities as they exist in the database after the insertion operation. This ensures that the
     * returned entities include any changes that might have been applied during the insertion process, such as
     * primary key, default values or triggers.</p>
     *
     * @param entities an iterable collection of entities to be inserted. Each entity in the collection must
     *                 be non-null and contain valid data for insertion.
     * @return the entities that were inserted into the database.
     * @throws PersistenceException if the insertion operation fails due to database issues, such as connectivity
     *                              problems, constraints violations, or invalid entity data.
     */
    @Override
    public List<E> insertAndFetch(@Nonnull Iterable<E> entities) {
        return findAllById(insertAndFetchIds(entities));
    }
}