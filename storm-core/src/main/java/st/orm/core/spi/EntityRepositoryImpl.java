/*
 * Copyright 2024 - 2025 the original author or authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package st.orm.core.spi;

import jakarta.annotation.Nonnull;
import jakarta.annotation.Nullable;
import st.orm.Entity;
import st.orm.Ref;
import st.orm.NoResultException;
import st.orm.NonUniqueResultException;
import st.orm.OptimisticLockException;
import st.orm.PersistenceException;
import st.orm.core.BatchCallback;
import st.orm.core.PreparedQuery;
import st.orm.core.Templates;
import st.orm.core.template.Column;
import st.orm.core.EntityRepository;
import st.orm.core.template.Model;
import st.orm.core.template.ORMTemplate;
import st.orm.core.template.QueryBuilder;
import st.orm.core.template.TemplateString;

import java.util.List;
import java.util.function.Supplier;
import java.util.stream.IntStream;
import java.util.stream.Stream;
import java.util.stream.StreamSupport;

import static st.orm.core.spi.Providers.deleteFrom;
import static st.orm.core.template.QueryBuilder.slice;

/**
 * Default implementation of {@link EntityRepository}.
 *
 * @param <E> the type of entity managed by this repository.
 * @param <ID> the type of the primary key of the entity.
 */
@SuppressWarnings("DuplicatedCode")
public class EntityRepositoryImpl<E extends Record & Entity<ID>, ID>
        extends BaseRepositoryImpl<E, ID>
        implements EntityRepository<E, ID> {

    protected final int defaultBatchSize;
    protected final boolean autoGeneratedPrimaryKey;

    public EntityRepositoryImpl(@Nonnull ORMTemplate ormTemplate, @Nonnull Model<E, ID> model) {
        super(ormTemplate, model);
        this.defaultBatchSize = 1000;
        this.autoGeneratedPrimaryKey = model.columns().stream()
                .filter(Column::primaryKey)
                .anyMatch(Column::autoGenerated);
    }

    protected E validateInsert(@Nonnull E entity) {
        if (autoGeneratedPrimaryKey) {
            if (!model.isDefaultPrimaryKey(entity.id())) {
                throw new PersistenceException("Primary key must not be set for auto-generated primary keys for inserts.");
            }
        } else {
            if (model.isDefaultPrimaryKey(entity.id())) {
                throw new PersistenceException("Primary key must be set for non-auto-generated primary keys for inserts.");
            }
        }
        return entity;
    }

    protected E validateInsert(@Nonnull E entity, boolean ignoreAutoGenerate) {
        if (!ignoreAutoGenerate) {
            return validateInsert(entity);
        }
        if (model.isDefaultPrimaryKey(entity.id())) {
            throw new PersistenceException("Primary key must be set.");
        }
        return entity;
    }

    protected E validateUpdate(@Nonnull E entity) {
        if (model.isDefaultPrimaryKey(entity.id())) {
            throw new PersistenceException("Primary key must be set for updates.");
        }
        return entity;
    }

    protected E validateDelete(@Nonnull E entity) {
        if (model.isDefaultPrimaryKey(entity.id())) {
            throw new PersistenceException("Primary key must be set for deletes.");
        }
        return entity;
    }

    /**
     * Returns the entity model associated with this repository.
     *
     * @return the entity model.
     */
    @Override
    public Model<E, ID> model() {
        return model;
    }

    /**
     * Creates a new ref entity instance for the specified entity.
     *
     * <p>This method wraps a fully loaded entity in a lightweight reference. Although the complete entity is provided,
     * the returned ref retains only the primary key for identification. In this case, calling {@link Ref#fetch()} will
     * return the full entity (which is already loaded), ensuring a consistent API for accessing entity records on
     * demand. This approach supports lazy-loading scenarios where only the identifier is needed initially.</p>
     *
     * @param entity the entity to wrap in a ref.
     * @return a ref entity instance containing the primary key of the provided entity.
     * @since 1.3
     */
    @Override
    public Ref<E> ref(@Nonnull E entity) {
        return ormTemplate.ref(entity, entity.id());
    }

    /**
     * Unloads the given entity from memory by converting it into a lightweight ref containing only its primary key.
     *
     * <p>This method discards the full entity data and returns a ref that encapsulates just the primary key. The actual
     * record is not retained in memory, but can be retrieved on demand by calling {@link Ref#fetch()}, which will
     * trigger a new database call. This approach is particularly useful when you need to minimize memory usage while
     * keeping the option to re-fetch the complete record later.</p>
     *
     * @param entity the entity to unload into a lightweight ref.
     * @return a ref containing only the primary key of the entity, allowing the full record to be fetched again when
     * needed.
     * @since 1.3
     */
    @Override
    public Ref<E> unload(@Nonnull E entity) {
        return ref(entity.id());
    }

    /**
     * Creates a new query builder for delete entities of the type managed by this repository.
     *
     * @return a new query builder for the entity type.
     */
    @Override
    public QueryBuilder<E, ?, ID> delete() {
        return deleteFrom(ormTemplate, model.type(), () -> model);
    }

    /**
     * Inserts an entity into the database.
     *
     * <p>This method adds a new entity to the database. It ensures that the entity is persisted according to the defined
     * database constraints and entity model. It's critical for the entity to be fully initialized as per the entity
     * model requirements.</p>
     *
     * @param entity the entity to insert. The entity must satisfy all model constraints.
     * @throws PersistenceException if the insert operation fails. This can happen due to a variety of reasons,
     *                              including database constraints violations, connectivity issues, or if the entity parameter is null.
     */
    @Override
    public void insert(@Nonnull E entity) {
        validateInsert(entity);
        var query = ormTemplate.query(TemplateString.raw("""
                INSERT INTO \0
                VALUES \0""", model.type(), entity));
        if (query.executeUpdate() != 1) {
            throw new PersistenceException("Insert failed.");
        }
    }

    /**
     * Inserts an entity into the database.
     *
     * <p>This method adds a new entity to the database. It ensures that the entity is persisted according to the defined
     * database constraints and entity model. It's critical for the entity to be fully initialized as per the entity
     * model requirements.</p>
     *
     * @param entity the entity to insert. The entity must satisfy all model constraints.
     * @param ignoreAutoGenerate true to ignore the auto-generate flag on the primary key and explicitly insert the
     *                           provided primary key value. Use this flag only when intentionally providing the primary
     *                           key value (e.g., migrations, data exports).
     * @throws PersistenceException if the insert operation fails. This can happen due to a variety of reasons,
     *                              including database constraints violations, connectivity issues, or if the entity parameter is null.
     */
    @Override
    public void insert(@Nonnull E entity, boolean ignoreAutoGenerate) {
        validateInsert(entity, ignoreAutoGenerate);
        var query = ormTemplate.query(TemplateString.raw("""
                INSERT INTO \0
                VALUES \0""", Templates.insert(model.type(), ignoreAutoGenerate), Templates.values(entity, ignoreAutoGenerate)));
        if (query.executeUpdate() != 1) {
            throw new PersistenceException("Insert failed.");
        }
    }

    /**
     * Inserts an entity into the database and returns its primary key.
     *
     * <p>This method adds a new entity to the database and upon successful insertion, returns the primary key assigned to
     * the entity when the primary key is generated by the database (e.g., auto-incremented). Otherwise, if the primary
     * key is not generated by the database, the method returns an empty optional.</p>
     *
     * @param entity the entity to insert. The entity must satisfy all model constraints.
     * @return the generated primary key of the successfully inserted entity.
     * @throws PersistenceException if the insert operation fails for reasons such as database constraints violations,
     *                              connectivity issues, or if the entity parameter is null.
     */
    @Override
    public ID insertAndFetchId(@Nonnull E entity) {
        validateInsert(entity);
        try (var query = ormTemplate.query(TemplateString.raw("""
                INSERT INTO \0
                VALUES \0""", model.type(), entity)).prepare()) {
            if (query.executeUpdate() != 1) {
                throw new PersistenceException("Insert failed.");
            }
            return singleResult(autoGeneratedPrimaryKey
                    ? query.getGeneratedKeys(model.primaryKeyType())
                    : Stream.of(entity.id()));
        }
    }

    /**
     * Inserts a single entity into the database and returns the inserted entity with its current state.
     *
     * <p>This method inserts the provided entity into the database. Upon successful insertion, it returns
     * the entity as it exists in the database after the operation. This ensures that the returned entity
     * includes any modifications applied during the insertion process, such as generated primary keys,
     * default values, or other automatic changes triggered by the database.</p>
     *
     * @param entity the entity to be inserted. The entity must be non-null and contain valid data for insertion
     *               into the database.
     * @return the inserted entity, reflecting its state in the database after insertion. This includes any
     *         database-applied changes such as primary key assignments or default values.
     * @throws PersistenceException if the insertion operation fails due to database issues, such as connectivity
     *                              problems, constraints violations, or invalid entity data.
     */
    @Override
    public E insertAndFetch(@Nonnull E entity) {
        return getById(insertAndFetchId(entity));
    }

    /**
     * Updates a single entity in the database.
     *
     * <p>This method updates the provided entity in the database, modifying its existing record to reflect the
     * current state of the entity. It is intended for cases where only one entity needs to be updated.</p>
     *
     * @param entity the entity to be updated. The entity must be non-null and contain valid data for updating
     *               its corresponding record in the database.
     * @throws PersistenceException if the update operation fails due to database issues, such as connectivity
     *                              problems, constraints violations, or invalid entity data.
     */
    @Override
    public void update(@Nonnull E entity) {
        validateUpdate(entity);
        var query = ormTemplate.query(TemplateString.raw("""
                UPDATE \0
                SET \0
                WHERE \0""", model.type(), entity, entity));
        int result = query.executeUpdate();
        if (query.isVersionAware() && result == 0) {
            throw new OptimisticLockException("Update failed due to optimistic lock.");
        } else if (result != 1) {
            throw new PersistenceException("Update failed.");
        }
    }

    /**
     * Updates a single entity in the database and returns the updated entity with its current state.
     *
     * <p>This method updates the provided entity in the database and, upon successful completion,
     * returns the entity as it exists in the database after the update operation. This ensures that the returned
     * entity reflects any modifications applied during the update process, such as updated timestamps,
     * versioning, or other automatic changes triggered by the database.</p>
     *
     * @param entity the entity to be updated. The entity must be non-null and contain valid data for updating
     *               its corresponding record in the database.
     * @return the updated entity, reflecting its state in the database after the update. This includes any
     *         database-applied changes such as modified timestamps or version numbers.
     * @throws PersistenceException if the update operation fails due to database issues, such as connectivity
     *                              problems, constraints violations, or invalid entity data.
     */
    @Override
    public E updateAndFetch(@Nonnull E entity) {
        update(entity);
        return getById(entity.id());
    }

    private PersistenceException upsertNotAvailable() {
        return new PersistenceException("Upsert is not available for the default implementation.");
    }

    /**
     * Inserts or updates a single entity in the database.
     *
     * <p>This method performs an "upsert" operation on the provided entity. If the entity does not already exist
     * in the database, it will be inserted. If it does exist, it will be updated to reflect the current state of
     * the entity. This approach ensures that the entity is either created or brought up-to-date, depending on
     * its existence in the database.</p>
     *
     * @param entity the entity to be inserted or updated. The entity must be non-null and contain valid data
     *               for insertion or update in the database.
     * @throws PersistenceException if the upsert operation fails due to database issues, such as connectivity
     *                              problems, constraints violations, or invalid entity data.
     */
    @Override
    public void upsert(@Nonnull E entity) {
        throw upsertNotAvailable();
    }

    /**
     * Inserts or updates a single entity in the database and returns its ID.
     *
     * <p>This method performs an "upsert" operation on the provided entity. If the entity does not already exist
     * in the database, it will be inserted; if it exists, it will be updated. Upon successful completion,
     * the method returns the ID of the entity as stored in the database. This approach ensures that the entity
     * is either created or brought up-to-date, depending on its existence in the database.</p>
     *
     * @param entity the entity to be inserted or updated. The entity must be non-null and contain valid data
     *               for insertion or update in the database.
     * @return the ID of the upserted entity, reflecting its identifier in the database.
     * @throws PersistenceException if the upsert operation fails due to database issues, such as connectivity
     *                              problems, constraints violations, or invalid entity data.
     */
    @Override
    public ID upsertAndFetchId(@Nonnull E entity) {
        throw upsertNotAvailable();
    }

    /**
     * Inserts or updates a single entity in the database and returns the entity with its current state.
     *
     * <p>This method performs an "upsert" operation on the provided entity. If the entity does not already exist
     * in the database, it will be inserted; if it exists, it will be updated. Upon successful completion,
     * the method returns the entity as it exists in the database after the upsert operation. This ensures that
     * the returned entity reflects any modifications applied during the upsert process, such as generated primary keys,
     * updated timestamps, or default values set by the database.</p>
     *
     * @param entity the entity to be inserted or updated. The entity must be non-null and contain valid data
     *               for insertion or update in the database.
     * @return the upserted entity, reflecting its current state in the database. This includes any
     *         database-applied changes, such as primary key assignments, default values, or timestamp updates.
     * @throws PersistenceException if the upsert operation fails due to database issues, such as connectivity
     *                              problems, constraints violations, or invalid entity data.
     */
    @Override
    public E upsertAndFetch(@Nonnull E entity) {
        throw upsertNotAvailable();
    }

    /**
     * Deletes an entity from the database.
     *
     * <p>This method removes an existing entity from the database. It is important to ensure that the entity passed for
     * deletion exists in the database and is correctly identified by its primary key.</p>
     *
     * @param entity the entity to delete. The entity must exist in the database and should be correctly identified by
     *               its primary key.
     * @throws PersistenceException if the deletion operation fails. Reasons for failure might include the entity not
     *                              being found in the database, violations of database constraints, connectivity
     *                              issues, or if the entity parameter is null.
     */
    @Override
    public void delete(@Nonnull E entity) {
        validateDelete(entity);
        // Don't use query builder to prevent WHERE IN clause.
        int result = ormTemplate.query(TemplateString.raw("""
                DELETE FROM \0
                WHERE \0""", model.type(), entity))
                .executeUpdate();
        if (result != 1) {
            throw new PersistenceException("Delete failed.");
        }
    }

    /**
     * Deletes an entity from the database based on its primary key.
     *
     * <p>This method removes an existing entity from the database. It is important to ensure that the entity passed for
     * deletion exists in the database.</p>
     *
     * @param id the primary key of the entity to delete.
     * @throws PersistenceException if the deletion operation fails. Reasons for failure might include the entity not
     *                              being found in the database, violations of database constraints, connectivity
     *                              issues, or if the entity parameter is null.
     */
    @Override
    public void deleteById(@Nonnull ID id) {
        // Don't use query builder to prevent WHERE IN clause.
        int result = ormTemplate.query(TemplateString.raw("""
                DELETE FROM \0
                WHERE \0""", model.type(), id))
            .executeUpdate();
        if (result != 1) {
            throw new PersistenceException("Delete failed.");
        }
    }

    /**
     * Deletes an entity from the database.
     *
     * <p>This method removes an existing entity from the database. It is important to ensure that the entity passed for
     * deletion exists in the database and is correctly identified by its primary key.</p>
     *
     * @param ref the entity to delete. The entity must exist in the database and should be correctly identified by
     *            its ref.
     * @throws PersistenceException if the deletion operation fails. Reasons for failure might include the entity not
     *                              being found in the database, violations of database constraints, connectivity
     *                              issues, or if the entity parameter is null.
     */
    @Override
    public void deleteByRef(@Nonnull Ref<E> ref) {
        // Don't use query builder to prevent WHERE IN clause.
        int result = ormTemplate.query(TemplateString.raw("""
                DELETE FROM \0
                WHERE \0""", model.type(), ref))
                .executeUpdate();
        if (result != 1) {
            throw new PersistenceException("Delete failed.");
        }
    }

    /**
     * Deletes all entities from the database.
     *
     * <p>This method performs a bulk deletion operation, removing all instances of the entities managed by this
     * repository from the database.</p>
     *
     * @throws PersistenceException if the bulk deletion operation fails. Failure can occur for several reasons,
     *                              including but not limited to database access issues, transaction failures, or
     *                              underlying database constraints that prevent the deletion of certain records.
     */
    @Override
    public void deleteAll() {
        // Don't use query builder to prevent WHERE IN clause.
        ormTemplate.query(TemplateString.raw("DELETE FROM \0", model.type()))
                .safe() // Omission of WHERE clause is intentional.
                .executeUpdate();
    }

    // List based methods.

    /**
     * Inserts a collection of entities into the database in batches.
     *
     * <p>This method processes the provided entities in batches, optimizing insertion for larger collections by
     * reducing database overhead. Batch processing helps ensure that even large numbers of entities can be
     * inserted efficiently and minimizes potential memory and performance issues.</p>
     *
     * @param entities an iterable collection of entities to be inserted. Each entity in the collection must
     *                 be non-null and contain valid data for insertion.
     * @throws PersistenceException if the insertion operation fails due to database issues, such as connectivity
     *                              problems, constraints violations, or invalid entity data.
     */
    @Override
    public void insert(@Nonnull Iterable<E> entities) {
        insert(toStream(entities), defaultBatchSize);
    }

    /**
     * Inserts a collection of entities into the database in batches.
     *
     * <p>This method processes the provided entities in batches, optimizing insertion for larger collections by
     * reducing database overhead. Batch processing helps ensure that even large numbers of entities can be
     * inserted efficiently and minimizes potential memory and performance issues.</p>
     *
     * @param entities an iterable collection of entities to be inserted. Each entity in the collection must
     *                 be non-null and contain valid data for insertion.
     * @param ignoreAutoGenerate true to ignore the auto-generate flag on the primary key and explicitly insert the
     *                           provided primary key value. Use this flag only when intentionally providing the primary
     *                           key value (e.g., migrations, data exports).
     * @throws PersistenceException if the insertion operation fails due to database issues, such as connectivity
     *                              problems, constraints violations, or invalid entity data.
     */
    @Override
    public void insert(@Nonnull Iterable<E> entities, boolean ignoreAutoGenerate) {
        insert(toStream(entities), defaultBatchSize, ignoreAutoGenerate);
    }

    /**
     * Inserts a collection of entities into the database in batches.
     *
     * <p>This method processes the provided entities in batches, optimizing insertion for larger collections by
     * reducing database overhead. Batch processing helps ensure that even large numbers of entities can be
     * inserted efficiently and minimizes potential memory and performance issues.</p>
     *
     * <p>Upon successful insertion, it returns the primary keys assigned to the entities when the primary keys are
     * generated by the database (e.g., auto-incremented). Otherwise, if the primary keys are not generated by the
     * database, the method returns an empty list.</p>
     *
     * @param entities an iterable collection of entities to be inserted. Each entity in the collection must
     *                 be non-null and contain valid data for insertion.
     * @return the primary keys assigned to the entities when the primary keys are generated by the database,
     * @throws PersistenceException if the insertion operation fails due to database issues, such as connectivity
     *                              problems, constraints violations, or invalid entity data.
     */
    @Override
    public List<ID> insertAndFetchIds(@Nonnull Iterable<E> entities) {
        var bindVars = ormTemplate.createBindVars();
        try (var query = ormTemplate.query(TemplateString.raw("""
                INSERT INTO \0
                VALUES \0""", model.type(), bindVars)).prepare()) {
            return slice(toStream(entities), defaultBatchSize,
                    batch -> {
                        batch.stream().map(this::validateInsert).map(Record.class::cast).forEach(query::addBatch);
                        int[] result = query.executeBatch();
                        if (IntStream.of(result).anyMatch(r -> r != 1)) {
                            throw new PersistenceException("Batch insert failed.");
                        }
                        // Stream is closed by the batch operation.
                        return autoGeneratedPrimaryKey
                                ? query.getGeneratedKeys(model.primaryKeyType())
                                : batch.stream().map(Entity::id);
            }).toList();
        }
    }

    /**
     * Inserts a collection of entities into the database in batches.
     *
     * <p>This method processes the provided entities in batches, optimizing insertion for larger collections by
     * reducing database overhead. Batch processing helps ensure that even large numbers of entities can be
     * inserted efficiently and minimizes potential memory and performance issues.</p>
     *
     * <p>Upon successful insertion, it returns the entities that were inserted. The returned entities reflect the
     * state of the entities as they exist in the database after the insertion operation. This ensures that the
     * returned entities include any changes that might have been applied during the insertion process, such as
     * primary key, default values or triggers.</p>
     *
     * @param entities an iterable collection of entities to be inserted. Each entity in the collection must
     *                 be non-null and contain valid data for insertion.
     * @return the entities that were inserted into the database.
     * @throws PersistenceException if the insertion operation fails due to database issues, such as connectivity
     *                              problems, constraints violations, or invalid entity data.
     */
    @Override
    public List<E> insertAndFetch(@Nonnull Iterable<E> entities) {
        return findAllById(insertAndFetchIds(entities));
    }

    /**
     * Updates a collection of entities in the database in batches.
     *
     * <p>This method processes the provided entities in batches to optimize updating of larger collections,
     * reducing database overhead and improving performance. Batch processing allows efficient handling of
     * bulk updates, minimizing memory and processing costs.</p>
     *
     * @param entities an iterable collection of entities to be updated. Each entity in the collection must
     *                 be non-null and contain valid, up-to-date data for modification in the database.
     * @throws PersistenceException if the update operation fails due to database issues, such as connectivity
     *                              problems, constraints violations, or invalid entity data.
     */
    @Override
    public void update(@Nonnull Iterable<E> entities) {
        update(toStream(entities), defaultBatchSize);
    }

    /**
     * Updates a collection of entities in the database in batches and returns a list of the updated entities.
     *
     * <p>This method processes the provided entities in batches, optimizing performance for larger collections by
     * reducing database overhead. Upon successful update, it returns the entities as they exist in the database
     * after the update operation. This ensures that the returned entities reflect any modifications applied during
     * the update process, such as updated timestamps, versioning, or other automatic changes made by the database.</p>
     *
     * @param entities an iterable collection of entities to be updated. Each entity in the collection must be non-null
     *                 and contain valid data for modification in the database.
     * @return a list of entities reflecting their state in the database after the update. The order of entities in
     *         the returned list is not guaranteed to match the order of the input collection.
     * @throws PersistenceException if the update operation fails due to database issues, such as connectivity problems,
     *                              constraints violations, or invalid entity data.
     */
    @Override
    public List<E> updateAndFetch(@Nonnull Iterable<E> entities) {
        update(entities);
        return findAllById(StreamSupport.stream(entities.spliterator(), false).map(Entity::id).toList());
    }

    /**
     * Inserts or updates a collection of entities in the database in batches.
     *
     * <p>This method processes the provided entities in batches, optimizing performance for larger collections by
     * reducing database overhead. For each entity, the method performs an "upsert" operation, meaning it will insert
     * the entity if it does not already exist in the database, or update it if it does. This approach ensures that
     * the entities are either created or brought up-to-date, depending on their existence in the database.</p>
     *
     * @param entities an iterable collection of entities to be inserted or updated. Each entity in the collection must
     *                 be non-null and contain valid data for insertion or update in the database.
     * @throws PersistenceException if the upsert operation fails due to database issues, such as connectivity problems,
     *                              constraints violations, or invalid entity data.
     */
    @Override
    public void upsert(@Nonnull Iterable<E> entities) {
        throw upsertNotAvailable();
    }

    /**
     * Inserts or updates a collection of entities in the database in batches and returns a list of their IDs.
     *
     * <p>This method processes the provided entities in batches to optimize performance for larger collections,
     * reducing database overhead. For each entity, the method performs an "upsert" operation, inserting the entity
     * if it does not already exist in the database, or updating it if it does. Upon successful completion,
     * the method returns a list of the IDs of the upserted entities, reflecting their identifiers as stored
     * in the database.</p>
     *
     * @param entities an iterable collection of entities to be inserted or updated. Each entity in the collection
     *                 must be non-null and contain valid data for insertion or update in the database.
     * @return a list of IDs corresponding to the upserted entities. The order of IDs in the returned list
     *         is not guaranteed to match the order of the input collection.
     * @throws PersistenceException if the upsert operation fails due to database issues, such as connectivity problems,
     *                              constraints violations, or invalid entity data.
     */
    @Override
    public List<ID> upsertAndFetchIds(@Nonnull Iterable<E> entities) {
        throw upsertNotAvailable();
    }

    /**
     * Inserts or updates a collection of entities in the database in batches and returns a list of the upserted
     * entities.
     *
     * <p>This method processes the provided entities in batches, optimizing performance for larger collections
     * by reducing database overhead. For each entity, it performs an "upsert" operation, inserting the entity if it
     * does not already exist in the database, or updating it if it does. Upon successful completion, it returns
     * the entities as they exist in the database after the operation. This ensures that the returned entities reflect
     * any changes applied during the upsert process, such as generated primary keys, updated timestamps, or default
     * values set by the database.</p>
     *
     * @param entities an iterable collection of entities to be inserted or updated. Each entity in the collection
     *                 must be non-null and contain valid data for insertion or update in the database.
     * @return a list of upserted entities reflecting their current state in the database. The order of entities
     *         in the returned list is not guaranteed to match the order of the input collection.
     * @throws PersistenceException if the upsert operation fails due to database issues, such as connectivity problems,
     *                              constraints violations, or invalid entity data.
     */
    @Override
    public List<E> upsertAndFetch(@Nonnull Iterable<E> entities) {
        throw upsertNotAvailable();
    }

    /**
     * Deletes a collection of entities from the database in batches.
     *
     * <p>This method processes the provided entities in batches to optimize performance when handling larger collections,
     * reducing database overhead. For each entity in the collection, the method removes the corresponding record from
     * the database, if it exists. Batch processing ensures efficient handling of deletions, particularly for large data sets.</p>
     *
     * @param entities an iterable collection of entities to be deleted. Each entity in the collection must be non-null
     *                 and represent a valid database record for deletion.
     * @throws PersistenceException if the deletion operation fails due to database issues, such as connectivity problems
     *                              or constraints violations.
     */
    @Override
    public void delete(@Nonnull Iterable<E> entities) {
        delete(toStream(entities), defaultBatchSize);
    }

    /**
     * Deletes a collection of entities from the database in batches.
     *
     * <p>This method processes the provided entities in batches to optimize performance when handling larger collections,
     * reducing database overhead. For each entity in the collection, the method removes the corresponding record from
     * the database, if it exists. Batch processing ensures efficient handling of deletions, particularly for large data sets.</p>
     *
     * @param refs an iterable collection of entities to be deleted. Each entity in the collection must be non-null
     *             and represent a valid database record for deletion.
     * @throws PersistenceException if the deletion operation fails due to database issues, such as connectivity problems
     *                              or constraints violations.
     */
    @Override
    public void deleteByRef(@Nonnull Iterable<Ref<E>> refs) {
        deleteByRef(toStream(refs), defaultBatchSize);
    }

    // Stream based methods. These methods operate in multiple batches.

    /**
     * Inserts entities in a batch mode to optimize performance and reduce database load.
     *
     * <p>For large volumes of entities, this method processes the inserts in multiple batches to ensure efficient
     * handling and minimize the impact on database resources. This structured approach facilitates the management of
     * large-scale insert operations.</p>
     *
     * @param entities the entities to insert. Must not be null.
     * @throws PersistenceException if the insert fails due to database constraints, connectivity issues, or if the
     *                              entities parameter is null.
     */
    @Override
    public void insert(@Nonnull Stream<E> entities) {
        insert(entities, defaultBatchSize);
    }

    /**
     * Inserts entities in a batch mode to optimize performance and reduce database load.
     *
     * <p>For large volumes of entities, this method processes the inserts in multiple batches to ensure efficient
     * handling and minimize the impact on database resources. This structured approach facilitates the management of
     * large-scale insert operations.</p>
     *
     * @param entities the entities to insert. Must not be null.
     * @param ignoreAutoGenerate true to ignore the auto-generate flag on the primary key and explicitly insert the
     *                           provided primary key value. Use this flag only when intentionally providing the primary
     *                           key value (e.g., migrations, data exports).
     * @throws PersistenceException if the insert fails due to database constraints, connectivity issues, or if the
     *                              entities parameter is null.
     */
    @Override
    public void insert(@Nonnull Stream<E> entities, boolean ignoreAutoGenerate) {
        insert(entities, defaultBatchSize, ignoreAutoGenerate);
    }

    /**
     * Inserts a stream of entities into the database, with the insertion process divided into batches of the specified
     * size.
     *
     * <p>This method inserts entities provided in a stream and uses the specified batch size for the insertion
     * operation.  Batching the inserts can greatly enhance performance by minimizing the number of database
     * interactions, especially useful when dealing with large volumes of data.</p>
     *
     * @param entities a stream of entities to insert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @param batchSize the size of the batches to use for the insertion operation. A larger batch size can improve
     *                  performance but may also increase the load on the database.
     * @throws PersistenceException if there is an error during the insertion operation, such as a violation of database
     *                              constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void insert(@Nonnull Stream<E> entities, int batchSize) {
        var bindVars = ormTemplate.createBindVars();
        try (var query = ormTemplate.query(TemplateString.raw("""
                INSERT INTO \0
                VALUES \0""", model.type(), bindVars)).prepare()) {
            slice(entities, batchSize).forEach(batch -> {
                batch.stream().map(this::validateInsert).map(Record.class::cast).forEach(query::addBatch);
                int[] result = query.executeBatch();
                if (IntStream.of(result).anyMatch(r -> r != 1)) {
                    throw new PersistenceException("Batch insert failed.");
                }
            });
        }
    }

    /**
     * Inserts a stream of entities into the database, with the insertion process divided into batches of the specified
     * size.
     *
     * <p>This method inserts entities provided in a stream and uses the specified batch size for the insertion
     * operation.  Batching the inserts can greatly enhance performance by minimizing the number of database
     * interactions, especially useful when dealing with large volumes of data.</p>
     *
     * @param entities a stream of entities to insert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @param batchSize the size of the batches to use for the insertion operation. A larger batch size can improve
     *                  performance but may also increase the load on the database.
     * @throws PersistenceException if there is an error during the insertion operation, such as a violation of database
     *                              constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void insert(@Nonnull Stream<E> entities, int batchSize, boolean ignoreAutoGenerate) {
        var bindVars = ormTemplate.createBindVars();
        try (var query = ormTemplate.query(TemplateString.raw("""
                INSERT INTO \0
                VALUES \0""",
                Templates.insert(model.type(), ignoreAutoGenerate),
                Templates.values(bindVars, ignoreAutoGenerate))).prepare()) {
            slice(entities, batchSize).forEach(batch -> {
                batch.stream().map(e -> validateInsert(e, ignoreAutoGenerate)).map(Record.class::cast).forEach(query::addBatch);
                int[] result = query.executeBatch();
                if (IntStream.of(result).anyMatch(r -> r != 1)) {
                    throw new PersistenceException("Batch insert failed.");
                }
            });
        }
    }

    /**
     * Inserts a stream of entities into the database using the default batch size and returns a stream of their
     * generated primary keys.
     *
     * <p>This method facilitates the insertion of entities and fetches their primary keys immediately after insertion.
     * This is particularly useful when the primary keys are generated by the database (e.g., auto-increment fields). It
     * uses the default batch size to optimize the number of database interactions.</p>
     *
     * @param entities a stream of entities to insert. Each entity must not be null and must conform to the model
     *                constraints.
     * @param callback the callback to process the IDs of the inserted entities in batches.
     * @throws PersistenceException if there is an error during the insertion or key retrieval operation, such as a
     *                              violation of database constraints, connectivity issues, or if any entity in the
     *                              stream is null.
     */
    @Override
    public void insertAndFetchIds(@Nonnull Stream<E> entities, @Nonnull BatchCallback<ID> callback) {
        insertAndFetchIds(entities, defaultBatchSize, callback);
    }

    /**
     * Inserts a stream of entities into the database using the default batch size and returns a stream of the inserted entities.
     *
     * <p>This method inserts entities into the database and retrieves them immediately after insertion. It is useful
     * for ensuring that the returned entities reflect any database-generated values or defaults. The insertion and
     * retrieval are performed using the default batch size to optimize database performance.</p>
     *
     * @param entities a stream of entities to insert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @param callback the callback to process the inserted entities, reflecting their new state in the database,
     *                 in batches.
     * @throws PersistenceException if there is an error during the insertion or retrieval operation, such as a
     *                              violation of database constraints, connectivity issues, or if any entity in the
     *                              stream is null.
     */
    @Override
    public void insertAndFetch(@Nonnull Stream<E> entities, @Nonnull BatchCallback<E> callback) {
        insertAndFetch(entities, defaultBatchSize, callback);
    }

    /**
     * Inserts a stream of entities into the database with the insertion process divided into batches of the specified size,
     * and returns a stream of their generated primary keys.
     *
     * <p>This method allows for efficient insertion of a large number of entities by batching them according to the
     * specified batch size. It also fetches the primary keys immediately after insertion, useful for entities with
     * database-generated keys.</p>
     *
     * @param entities a stream of entities to insert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @param batchSize the size of the batches to use for the insertion operation. A larger batch size can improve
     *                  performance but may also increase the load on the database.
     * @param callback the callback to process the IDs of the inserted entities in batches.
     * @throws PersistenceException if there is an error during the insertion or key retrieval operation, such as a
     *                              violation of database constraints, connectivity issues, or if any entity in the
     *                              stream is null.
     */
    @Override
    public void insertAndFetchIds(@Nonnull Stream<E> entities, int batchSize, @Nonnull BatchCallback<ID> callback) {
        var bindVars = ormTemplate.createBindVars();
        try (var query = ormTemplate.query(TemplateString.raw("""
                INSERT INTO \0
                VALUES \0""", model.type(), bindVars)).prepare()) {
            slice(entities, batchSize).forEach(batch -> {
                batch.stream().map(this::validateInsert).map(Record.class::cast).forEach(query::addBatch);
                int[] result = query.executeBatch();
                if (IntStream.of(result).anyMatch(r -> r != 1)) {
                    throw new PersistenceException("Batch insert failed.");
                }
                try (var generatedKeys = autoGeneratedPrimaryKey
                        ? query.getGeneratedKeys(model.primaryKeyType())
                        : batch.stream().map(Entity::id)) {
                    callback.process(generatedKeys);
                }
            });
        }
    }

    /**
     * Inserts a stream of entities into the database with the insertion process divided into batches of the specified size,
     * and returns a stream of the inserted entities.
     *
     * <p>This method provides an efficient way to insert a large number of entities by batching them according to the
     * specified batch size. It fetches the inserted entities immediately after insertion to ensure that the returned
     * entities reflect any database-generated values or defaults. This is particularly useful when database triggers or
     * default values are involved.</p>
     *
     * @param entities a stream of entities to insert. Each entity must not be null and must conform to the model
     *                 constraints.
     * @param batchSize the size of the batches to use for the insertion operation. A larger batch size can improve
     *                 performance but may also increase the load on the database.
     * @param callback the callback to process the inserted entities, reflecting their new state in the database,
     *                 in batches.
     * @throws PersistenceException if there is an error during the insertion or retrieval operation, such as a
     *                              violation of database constraints, connectivity issues, or if any entity in the
     *                              stream is null.
     */
    @Override
    public void insertAndFetch(@Nonnull Stream<E> entities, int batchSize, @Nonnull BatchCallback<E> callback) {
        insertAndFetchIds(entities, batchSize, ids -> callback.process(selectById(ids)));
    }

    /**
     * Updates a stream of entities in the database using the default batch size.
     *
     * <p>This method updates entities provided in a stream, optimizing the update process by batching them
     * with a default size. This helps to reduce the number of database operations and can significantly improve
     * performance when updating large numbers of entities.</p>
     *
     * @param entities a stream of entities to update. Each entity must not be null, must already exist in the database,
     *                 and must conform to the model constraints.
     * @throws PersistenceException if there is an error during the update operation, such as a violation of database
     *                              constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void update(@Nonnull Stream<E> entities) {
        update(entities, defaultBatchSize);
    }

    /**
     * Updates a stream of entities in the database, with the update process divided into batches of the specified size.
     *
     * <p>This method updates entities provided in a stream and uses the specified batch size for the update operation.
     * Batching the updates can greatly enhance performance by minimizing the number of database interactions,
     * especially useful when dealing with large volumes of data.</p>
     *
     * @param entities a stream of entities to update. Each entity must not be null, must already exist in the database,
     *                 and must conform to the model constraints.
     * @param batchSize the size of the batches to use for the update operation. A larger batch size can improve
     *                  performance but may also increase the load on the database.
     * @throws PersistenceException if there is an error during the update operation, such as a violation of database
     *                              constraints, connectivity issues, or if any entity in the stream is null.
     */
    @Override
    public void update(@Nonnull Stream<E> entities, int batchSize) {
        try (var query = prepareUpdateQuery()) {
            slice(entities, batchSize).forEach(batch -> updateAndFetch(batch, () -> query, null));
        }
    }

    /**
     * Updates a stream of entities in the database using the default batch size and returns a stream of the updated entities.
     *
     * <p>This method updates entities provided in a stream, optimizing the update process by batching them with the
     * default size. It fetches the updated entities immediately after updating to ensure that the returned entities
     * reflect any database-generated values or defaults. This is particularly useful when database triggers or default
     * values are involved.</p>
     *
     * @param entities a stream of entities to update. Each entity must not be null, must already exist in the database,
     *                 and must conform to the model constraints.
     * @param callback the callback to process the updated entities, reflecting their new state in the database,
     *                 in batches.
     * @throws PersistenceException if there is an error during the update or retrieval operation, such as a violation
     *                              of database constraints, connectivity issues, or if any entity in the stream is
     *                              null.
     */
    @Override
    public void updateAndFetch(@Nonnull Stream<E> entities, @Nonnull BatchCallback<E> callback) {
        updateAndFetch(entities, defaultBatchSize, callback);
    }

    /**
     * Updates a stream of entities in the database, with the update process divided into batches of the specified size,
     * and returns a stream of the updated entities.
     *
     * <p>This method updates entities provided in a stream and uses the specified batch size for the update operation.
     * Batching the updates can greatly enhance performance by minimizing the number of database interactions,
     * especially useful when dealing with large volumes of data. It fetches the updated entities immediately after
     * updating to ensure that the returned entities reflect any database-generated values or defaults.</p>
     *
     * @param entities a stream of entities to update. Each entity must not be null, must already exist in the database,
     *                 and must conform to the model constraints.
     * @param batchSize the size of the batches to use for the update operation. A larger batch size can improve
     *                  performance but may also increase the load on the database.
     * @param callback the callback to process the updated entities, reflecting their new state in the database,
     *                 in batches.
     * @throws PersistenceException if there is an error during the update or retrieval operation, such as a violation
     *                              of database constraints, connectivity issues, or if any entity in the stream is
     *                              null.
     */
    @Override
    public void updateAndFetch(@Nonnull Stream<E> entities, int batchSize, @Nonnull BatchCallback<E> callback) {
        try (var query = prepareUpdateQuery()) {
            slice(entities, batchSize).forEach(batch -> updateAndFetch(batch, () -> query, callback));
        }
    }

    protected PreparedQuery prepareUpdateQuery() {
        var bindVars = ormTemplate.createBindVars();
        return ormTemplate.query(TemplateString.raw("""
                UPDATE \0
                SET \0
                WHERE \0""", model.type(), bindVars, bindVars)).prepare();
    }

    protected void updateAndFetchIds(@Nonnull List<E> batch, @Nonnull Supplier<PreparedQuery> querySupplier, @Nullable BatchCallback<ID> callback) {
        if (!batch.isEmpty()) {
            var query = querySupplier.get();
            batch.stream().map(this::validateUpdate).map(Record.class::cast).forEach(query::addBatch);
            int[] result = query.executeBatch();
            if (query.isVersionAware() && IntStream.of(result).anyMatch(r -> r == 0)) {
                throw new OptimisticLockException("Update failed due to optimistic lock.");
            } else if (IntStream.of(result).anyMatch(r -> r != 1)) {
                throw new PersistenceException("Batch update failed.");
            }
        }
        if (callback != null) {
            callback.process(batch.stream().map(Entity::id));
        }
    }

    protected void updateAndFetch(@Nonnull List<E> batch, @Nonnull Supplier<PreparedQuery> query, @Nullable BatchCallback<E> callback) {
        updateAndFetchIds(batch, query, callback == null ? null : ids -> {
            try (var stream = selectById(ids)) {
                callback.process(stream);
            }
        });
    }

    /**
     * Inserts or updates a stream of entities in the database in batches.
     *
     * <p>This method processes the provided stream of entities in batches, performing an "upsert" operation on each.
     * For each entity, it will be inserted into the database if it does not already exist; if it does exist, it will
     * be updated to reflect the current state of the entity. Batch processing optimizes the performance of the
     * upsert operation for larger data sets by reducing database overhead.</p>
     *
     * @param entities a stream of entities to be inserted or updated. Each entity in the stream must be non-null
     *                 and contain valid data for insertion or update in the database.
     * @throws PersistenceException if the upsert operation fails due to database issues, such as connectivity
     *                              problems, constraints violations, or invalid entity data.
     */
    @Override
    public void upsert(@Nonnull Stream<E> entities) {
        throw upsertNotAvailable();
    }

    /**
     * Inserts or updates a stream of entities in the database in configurable batch sizes.
     *
     * <p>This method processes the provided stream of entities in batches, performing an "upsert" operation on each.
     * For each entity, it will be inserted if it does not already exist in the database, or updated if it does.
     * The batch size can be configured to control the number of entities processed in each database operation,
     * allowing for optimized performance and memory management based on system requirements.</p>
     *
     * @param entities a stream of entities to be inserted or updated. Each entity in the stream must be non-null
     *                 and contain valid data for insertion or update in the database.
     * @param batchSize the number of entities to process in each batch. A larger batch size may improve performance
     *                  but increase memory usage, while a smaller batch size may reduce memory usage but increase
     *                  the number of database operations.
     * @throws PersistenceException if the upsert operation fails due to database issues, such as connectivity
     *                              problems, constraints violations, or invalid entity data.
     */
    @Override
    public void upsert(@Nonnull Stream<E> entities, int batchSize) {
        throw upsertNotAvailable();
    }

    /**
     * Inserts or updates a stream of entities in the database in batches and retrieves their IDs through a callback.
     *
     * <p>This method processes the provided stream of entities in batches, performing an "upsert" operation on each entity.
     * For each entity, it will be inserted if it does not already exist in the database or updated if it does. After
     * each batch operation, the IDs of the upserted entities are passed to the provided callback, allowing for
     * customized handling of the IDs as they are retrieved.</p>
     *
     * @param entities a stream of entities to be inserted or updated. Each entity in the stream must be non-null and
     *                 contain valid data for insertion or update in the database.
     * @param callback the callback to process the IDs of the upserted entities in batches.
     * @throws PersistenceException if the upsert operation fails due to database issues, such as connectivity problems,
     *                              constraints violations, or invalid entity data.
     */
    @Override
    public void upsertAndFetchIds(@Nonnull Stream<E> entities, @Nonnull BatchCallback<ID> callback) {
        throw upsertNotAvailable();
    }

    /**
     * Inserts or updates a stream of entities in the database in batches and retrieves the updated entities through a callback.
     *
     * <p>This method processes the provided stream of entities in batches, performing an "upsert" operation on each entity.
     * For each entity, it will be inserted if it does not already exist in the database or updated if it does. After
     * each batch operation, the updated entities are passed to the provided callback, allowing for customized handling
     * of the entities as they are retrieved. The entities returned reflect their current state in the database, including
     * any changes such as generated primary keys, timestamps, or default values set by the database during the upsert process.</p>
     *
     * @param entities a stream of entities to be inserted or updated. Each entity in the stream must be non-null and
     *                 contain valid data for insertion or update in the database.
     * @param callback the callback to process the upserted entities, reflecting their new state in the database,
     *                 in batches.
     * @throws PersistenceException if the upsert operation fails due to database issues, such as connectivity problems,
     *                              constraints violations, or invalid entity data.
     */
    @Override
    public void upsertAndFetch(@Nonnull Stream<E> entities, @Nonnull BatchCallback<E> callback) {
        throw upsertNotAvailable();
    }

    /**
     * Inserts or updates a stream of entities in the database in configurable batch sizes and retrieves their IDs through a callback.
     *
     * <p>This method processes the provided stream of entities in batches, performing an "upsert" operation on each entity.
     * For each entity, it will be inserted if it does not already exist in the database or updated if it does. The batch size
     * parameter allows control over the number of entities processed in each batch, optimizing memory and performance based
     * on system requirements. After each batch operation, the IDs of the upserted entities are passed to the provided
     * callback, allowing for customized handling of the IDs as they are retrieved.</p>
     *
     * @param entities a stream of entities to be inserted or updated. Each entity in the stream must be non-null and contain
     *                 valid data for insertion or update in the database.
     * @param batchSize the number of entities to process in each batch. Adjusting the batch size can optimize performance
     *                  and memory usage, with larger sizes potentially improving performance but using more memory.
     * @param callback the callback to process the IDs of the upserted entities in batches.
     * @throws PersistenceException if the upsert operation fails due to database issues, such as connectivity problems,
     *                              constraints violations, or invalid entity data.
     */
    @Override
    public void upsertAndFetchIds(@Nonnull Stream<E> entities, int batchSize, @Nonnull BatchCallback<ID> callback) {
        throw upsertNotAvailable();
    }

    /**
     * Inserts or updates a stream of entities in the database in configurable batch sizes and retrieves the updated entities through a callback.
     *
     * <p>This method processes the provided stream of entities in batches, performing an "upsert" operation on each entity.
     * For each entity, it will be inserted if it does not already exist in the database or updated if it does. The
     * `batchSize` parameter allows control over the number of entities processed in each batch, optimizing performance
     * and memory usage based on system requirements. After each batch operation, the updated entities are passed to
     * the provided callback, allowing for customized handling of the entities as they are retrieved. The entities
     * returned reflect their current state in the database, including any changes such as generated primary keys,
     * timestamps, or default values applied during the upsert process.</p>
     *
     * @param entities a stream of entities to be inserted or updated. Each entity in the stream must be non-null and
     *                 contain valid data for insertion or update in the database.
     * @param batchSize the number of entities to process in each batch. Adjusting the batch size can optimize performance
     *                  and memory usage, with larger sizes potentially improving performance but using more memory.
     * @param callback the callback to process the upserted entities, reflecting their new state in the database,
     *                 in batches.
     * @throws PersistenceException if the upsert operation fails due to database issues, such as connectivity problems,
     *                              constraints violations, or invalid entity data.
     */
    @Override
    public void upsertAndFetch(@Nonnull Stream<E> entities, int batchSize, @Nonnull BatchCallback<E> callback) {
        throw upsertNotAvailable();
    }

    /**
     * Deletes a stream of entities from the database in batches.
     *
     * <p>This method processes the provided stream of entities in batches to optimize performance for larger
     * data sets, reducing database overhead during deletion. For each entity in the stream, the method removes
     * the corresponding record from the database, if it exists. Batch processing allows efficient handling
     * of deletions, particularly for large collections of entities.</p>
     *
     * @param entities a stream of entities to be deleted. Each entity in the stream must be non-null and represent
     *                 a valid database record for deletion.
     * @throws PersistenceException if the deletion operation fails due to database issues, such as connectivity problems
     *                              or constraints violations.
     */
    @Override
    public void delete(@Nonnull Stream<E> entities) {
        delete(entities, defaultBatchSize);
    }

    /**
     * Deletes a stream of entities from the database in configurable batch sizes.
     *
     * <p>This method processes the provided stream of entities in batches, with the size of each batch specified
     * by the `batchSize` parameter. This allows for control over the number of entities deleted in each database
     * operation, optimizing performance and memory usage based on system requirements. For each entity in the
     * stream, the method removes the corresponding record from the database, if it exists.</p>
     *
     * @param entities a stream of entities to be deleted. Each entity in the stream must be non-null and represent
     *                 a valid database record for deletion.
     * @param batchSize the number of entities to process in each batch. Larger batch sizes may improve performance
     *                  but require more memory, while smaller batch sizes may reduce memory usage but increase
     *                  the number of database operations.
     * @throws PersistenceException if the deletion operation fails due to database issues, such as connectivity problems
     *                              or constraints violations.
     */
    @Override
    public void delete(@Nonnull Stream<E> entities, int batchSize) {
        var bindVars = ormTemplate.createBindVars();
        try (var query = ormTemplate.query(TemplateString.raw("""
                DELETE FROM \0
                WHERE \0""", model.type(), bindVars)).prepare()) {
            slice(entities, batchSize).forEach(slice -> {
                slice.stream().map(this::validateDelete).map(Record.class::cast).forEach(query::addBatch);
                int[] result = query.executeBatch();
                if (IntStream.of(result).anyMatch(r -> r != 1)) {
                    throw new PersistenceException("Batch delete failed.");
                }
            });
        }
    }

    /**
     * Deletes a stream of entities from the database in batches.
     *
     * <p>This method processes the provided stream of entities in batches to optimize performance for larger
     * data sets, reducing database overhead during deletion. For each entity in the stream, the method removes
     * the corresponding record from the database, if it exists. Batch processing allows efficient handling
     * of deletions, particularly for large collections of entities.</p>
     *
     * @param refs a stream of entities to be deleted. Each entity in the stream must be non-null and represent
     *             a valid database record for deletion.
     * @throws PersistenceException if the deletion operation fails due to database issues, such as connectivity problems
     *                              or constraints violations.
     */
    @Override
    public void deleteByRef(@Nonnull Stream<Ref<E>> refs) {
        deleteByRef(refs, defaultBatchSize);
    }

    /**
     * Deletes a stream of entities from the database in configurable batch sizes.
     *
     * <p>This method processes the provided stream of entities in batches, with the size of each batch specified
     * by the `batchSize` parameter. This allows for control over the number of entities deleted in each database
     * operation, optimizing performance and memory usage based on system requirements. For each entity in the
     * stream, the method removes the corresponding record from the database, if it exists.</p>
     *
     * @param refs a stream of entities to be deleted. Each entity in the stream must be non-null and represent
     *              valid database record for deletion.
     * @param batchSize the number of entities to process in each batch. Larger batch sizes may improve performance
     *                  but require more memory, while smaller batch sizes may reduce memory usage but increase
     *                  the number of database operations.
     * @throws PersistenceException if the deletion operation fails due to database issues, such as connectivity problems
     *                              or constraints violations.
     */
    @Override
    public void deleteByRef(@Nonnull Stream<Ref<E>> refs, int batchSize) {
        slice(refs, batchSize).forEach(slice -> {
            // Don't use query builder to prevent WHERE IN clause.
            int result = ormTemplate.query(TemplateString.raw("""
                    DELETE FROM \0
                    WHERE \0""", model.type(), slice))
                .executeUpdate();
            if (result < slice.stream().distinct().count()) {
                throw new PersistenceException("Delete failed.");
            }
        });
    }

    /**
     * Returns the single result of the stream.
     *
     * @param stream the stream to get the single result from.
     * @return the single result of the stream.
     * @param <T> the type of the result.
     * @throws NoResultException if there is no result.
     * @throws NonUniqueResultException if more than one result.
     */
    private <T> T singleResult(Stream<T> stream) {
        try (stream) {
            return stream
                    .reduce((a, b) -> {
                        throw new NonUniqueResultException("Expected single result, but found more than one.");
                    }).orElseThrow(() -> new NoResultException("Expected single result, but found none."));
        }
    }
}
