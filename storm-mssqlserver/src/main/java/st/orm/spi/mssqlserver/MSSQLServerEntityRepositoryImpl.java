/*
 * Copyright 2024 - 2026 the original author or authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package st.orm.spi.mssqlserver;

import jakarta.annotation.Nonnull;
import jakarta.annotation.Nullable;
import st.orm.Metamodel;
import st.orm.core.repository.EntityRepository;
import st.orm.core.template.PreparedQuery;
import st.orm.core.spi.EntityCache;
import st.orm.core.repository.impl.EntityRepositoryImpl;
import st.orm.core.template.Column;
import st.orm.core.template.Model;
import st.orm.core.template.ORMTemplate;
import st.orm.core.template.Query;
import st.orm.core.template.SqlTemplateException;
import st.orm.core.template.TemplateString;
import st.orm.core.template.impl.LazySupplier;
import st.orm.BindVars;
import st.orm.Entity;
import st.orm.PersistenceException;

import java.math.BigInteger;
import java.sql.Timestamp;
import java.time.Instant;
import java.util.ArrayList;
import java.util.Calendar;
import java.util.Date;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Set;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicReference;
import java.util.stream.IntStream;
import java.util.stream.Stream;

import static java.util.function.Function.identity;
import static java.util.function.Predicate.not;
import static java.util.stream.Collectors.joining;
import static st.orm.GenerationStrategy.IDENTITY;
import static st.orm.GenerationStrategy.NONE;
import static st.orm.GenerationStrategy.SEQUENCE;
import static st.orm.core.repository.impl.DirtySupport.getMaxShapes;
import static st.orm.core.repository.impl.StreamSupport.partitioned;
import static st.orm.core.template.Templates.bindVar;
import static st.orm.core.template.SqlInterceptor.intercept;
import static st.orm.core.template.TemplateString.combine;
import static st.orm.core.template.TemplateString.raw;
import static st.orm.core.template.TemplateString.wrap;
import static st.orm.core.template.impl.StringTemplates.flatten;

/**
 * Implementation of {@link EntityRepository} for SQL Server.
 */
public class MSSQLServerEntityRepositoryImpl<E extends Entity<ID>, ID>
        extends EntityRepositoryImpl<E, ID> {

    public MSSQLServerEntityRepositoryImpl(@Nonnull ORMTemplate ormTemplate, @Nonnull Model<E, ID> model) {
        super(ormTemplate, model);
    }

    /**
     * Constructs a version update string for a version column. For numeric types the column is incremented,
     * for date/timestamp types CURRENT_TIMESTAMP is used.
     */
    private String getVersionString(@Nonnull Column column) {
        String columnName = column.qualifiedName(ormTemplate.dialect());
        String updateExpression = switch (column.type()) {
            case Class<?> c when Integer.TYPE.isAssignableFrom(c)
                    || Long.TYPE.isAssignableFrom(c)
                    || Integer.class.isAssignableFrom(c)
                    || Long.class.isAssignableFrom(c)
                    || BigInteger.class.isAssignableFrom(c) -> "t.%s + 1".formatted(columnName);
            case Class<?> c when Instant.class.isAssignableFrom(c)
                    || Date.class.isAssignableFrom(c)
                    || Calendar.class.isAssignableFrom(c)
                    || Timestamp.class.isAssignableFrom(c) -> "CURRENT_TIMESTAMP";
            default ->
                    throw new PersistenceException("Unsupported version type: %s.".formatted(column.type().getSimpleName()));
        };
        return "t.%s = %s".formatted(columnName, updateExpression);
    }

    /**
     * Builds a SELECT clause for the merge source based on the entity’s current values.
     * (Note: Unlike Oracle, SQL Server does not require a FROM DUAL clause.)
     */
    private TemplateString mergeSelect(@Nonnull E entity) {
        assert !isAutoGeneratedPrimaryKey();
        var dialect = ormTemplate.dialect();
        var duplicates = new HashSet<>(); // Ensure each column appears only once.
        try {
            var mapped = model.declaredValues(entity);
            return mapped.entrySet()
                    .stream()
                    .filter(entry -> duplicates.add(entry.getKey().name()))
                    .map(entry -> {
                        Object value = entry.getValue();
                        if (entry.getKey().primaryKey()) {
                            //noinspection unchecked
                            if (model.isDefaultPrimaryKey((ID) value)) {
                                value = null;   // Always pass NULL to force a mismatch.
                            }
                        }
                        return combine(wrap(value), TemplateString.of(" AS %s".formatted(entry.getKey().qualifiedName(dialect))));
                    })
                    .reduce((left, right) -> combine(left, TemplateString.of(", "), right))
                    .map(t -> combine(TemplateString.of("SELECT "), t))
                    .orElseThrow();
        } catch (SqlTemplateException e) {
            throw new PersistenceException("Failed to map entity to SQL parameters.", e);
        }
    }

    /**
     * Builds a SELECT clause for the merge source based on bind variables.
     */
    private TemplateString mergeSelect(@Nonnull BindVars bindVars) {
        var values = new AtomicReference<Map<Column, ?>>();
        bindVars.setRecordListener(record -> {
            try {
                //noinspection unchecked
                values.setPlain(model.declaredValues((E) record));
            } catch (SqlTemplateException e) {
                throw new PersistenceException("Failed to map entity to SQL parameters.", e);
            }
        });
        var duplicates = new HashSet<>();
        return model.declaredColumns().stream()
                .filter(column -> duplicates.add(column.name()))
                .map(c -> combine(wrap(bindVar(bindVars, ignore -> values.getPlain().get(c))),
                        TemplateString.of(" AS %s".formatted(c.name()))))
                .reduce((left, right) -> combine(left, TemplateString.of(", "), right))
                .map(t -> combine(TemplateString.of("SELECT "), t))
                .orElseThrow();
    }

    /**
     * Builds a SELECT clause for the merge source based on entities.
     */
    private TemplateString mergeSelect(@Nonnull Iterable<E> entities) {
        assert generationStrategy == SEQUENCE;
        try {
            List<TemplateString> valuesTemplates = new ArrayList<>();
            for (E entity : entities) {
                var mapped = model.declaredValues(entity);
                var duplicates = new HashSet<>(); // Ensure each column appears only once.
                valuesTemplates.add(mapped.entrySet().stream()
                        .filter(entry -> duplicates.add(entry.getKey().name()))
                        .map(entry -> {
                            Column column = entry.getKey();
                            Object value = entry.getValue();
                            if (column.primaryKey()) {
                                //noinspection unchecked
                                if (model.isDefaultPrimaryKey((ID) value)) {
                                    value = null;   // Always pass NULL to force a mismatch.
                                }
                            }
                            return wrap(value);
                        })
                        .reduce((left, right) -> combine(left, TemplateString.of(", "), right))
                        .map(t -> combine(TemplateString.of("("), t, TemplateString.of(")")))
                        .orElseThrow());
            }
            return valuesTemplates.stream()
                    .reduce((left, right) -> combine(left, TemplateString.of(", "), right))
                    .map(t -> combine(TemplateString.of("VALUES "), t))
                    .orElseThrow();
        } catch (SqlTemplateException e) {
            throw new PersistenceException("Failed to map entity to SQL parameters.", e);
        }
    }

    /**
     * Builds a src clause for the merge source based on bind variables.
     */
    private TemplateString mergeSource() {
        var dialect = ormTemplate.dialect();
        var duplicates = new HashSet<>(); // Ensure each column appears only once.
        return model.declaredColumns().stream()
                .filter(column -> duplicates.add(column.name()))
                .map(entry -> TemplateString.of(entry.qualifiedName(dialect)))
                .reduce((left, right) -> combine(left, TemplateString.of(", "), right))
                .orElseThrow();
    }

    /**
     * Constructs the ON clause by equating primary key columns.
     */
    private TemplateString mergeOn() {
        var dialect = ormTemplate.dialect();
        var primaryKeys = model.declaredColumns().stream()
                .filter(Column::primaryKey)
                .toList();
        String sql = primaryKeys.stream()
                .map(c -> "t.%s = src.%s".formatted(c.qualifiedName(dialect), c.qualifiedName(dialect)))
                .collect(joining(" AND "));
        return TemplateString.of(sql);
    }

    /**
     * Constructs the UPDATE clause for the MERGE statement.
     */
    private TemplateString mergeUpdate(@Nonnull AtomicBoolean versionAware) {
        var dialect = ormTemplate.dialect();
        var duplicates = new HashSet<>();
        var args = model.declaredColumns().stream()
                .filter(not(Column::primaryKey))
                .filter(Column::updatable)
                .filter(column -> duplicates.add(column.name()))
                .map(column -> {
                    if (column.version()) {
                        versionAware.setPlain(true);
                        return getVersionString(column);
                    }
                    return "t.%s = src.%s".formatted(column.qualifiedName(dialect), column.qualifiedName(dialect));
                })
                .toList();
        if (args.isEmpty()) {
            return TemplateString.EMPTY;
        }
        String sql = args.stream().collect(joining(", ", "UPDATE SET ", ""));
        return TemplateString.of("\nWHEN MATCHED THEN\n\t%s".formatted(sql));
    }

    /**
     * Constructs the INSERT clause for the MERGE statement.
     */
    private TemplateString mergeInsert() {
        var dialect = ormTemplate.dialect();
        var insertDuplicates = new HashSet<>();
        var insertArgs = model.declaredColumns().stream()
                .filter(column -> !(column.generation() == IDENTITY || (column.generation() == SEQUENCE && column.sequence().isEmpty())))
                .map(Column::name)
                .filter(insertDuplicates::add)
                .toList();
        var valuesDuplicates = new HashSet<>();
        var valuesArgs = model.declaredColumns().stream()
                .filter(column -> valuesDuplicates.add(column.name()))
                .map(column -> {
                    if (column.generation() == IDENTITY || (column.generation() == SEQUENCE && column.sequence().isEmpty())) {
                        // For auto-generated primary keys, we do not insert a value.
                        return null;
                    }
                    if (!column.sequence().isEmpty()) {
                        return "NEXT VALUE FOR %s".formatted(dialect.getSafeIdentifier(column.sequence()));
                    }
                    return "src.%s".formatted(column.qualifiedName(dialect));
                })
                .filter(Objects::nonNull)
                .toList();
        if (insertArgs.isEmpty()) {
            return TemplateString.EMPTY;
        }
        String insertSql = String.join(", ", insertArgs);
        String valuesSql = String.join(", ", valuesArgs);
        String sql = "\n\tINSERT (%s)\n\tVALUES (%s)".formatted(insertSql, valuesSql);
        return TemplateString.of("\nWHEN NOT MATCHED THEN%s".formatted(sql));
    }

    /**
     * Validates the entity for an upsert operation.
     */
    protected E validateUpsert(@Nonnull E entity) {
        if (isAutoGeneratedPrimaryKey() && !model.isDefaultPrimaryKey(entity.id())) {
            throw new PersistenceException("Primary key must not be set for auto-generated primary keys for upserts.");
        }
        return entity;
    }

    /**
     * Inserts or updates a single entity in the database.
     */
    @Override
    public void upsert(@Nonnull E entity) {
        if (isUpdate(entity)) {
            update(entity);
            return;
        }
        if (isAutoGeneratedPrimaryKey()) {
            // In auto-generated mode, an insert is performed.
            insert(entity);
            return;
        }
        validateUpsert(entity);
        entityCache().ifPresent(cache -> {
            if (!model.isDefaultPrimaryKey(entity.id())) {
                cache.remove(entity.id());
            }
        });
        var versionAware = new AtomicBoolean();
        intercept(sql -> sql.versionAware(versionAware.getPlain()), () -> {
            // Note: SQL Server's MERGE syntax does not require a FROM DUAL clause.
            var query = ormTemplate.query(flatten(raw("""
                MERGE INTO \0 t
                USING (\0) src
                ON (\0)\0\0;""", model.type(), mergeSelect(entity), mergeOn(), mergeUpdate(versionAware), mergeInsert()))).managed();
                query.executeUpdate();
        });
    }

    /**
     * Inserts or updates a single entity and returns its ID.
     */
    @Override
    public ID upsertAndFetchId(@Nonnull E entity) {
        if (isUpdate(entity)) {
            update(entity);
            return entity.id();
        }
        if (isAutoGeneratedPrimaryKey()) {
            return insertAndFetchId(entity);
        }
        validateUpsert(entity);
        entityCache().ifPresent(cache -> {
            if (!model.isDefaultPrimaryKey(entity.id())) {
                cache.remove(entity.id());
            }
        });
        var versionAware = new AtomicBoolean();
        intercept(sql -> sql.versionAware(versionAware.getPlain()), () -> {
            var query = ormTemplate.query(flatten(raw("""
                MERGE INTO \0 t
                USING (\0) src
                ON (\0)\0\0;""", model.type(), mergeSelect(entity), mergeOn(), mergeUpdate(versionAware), mergeInsert())))
                    .managed();
            query.executeUpdate();
        });
        return entity.id();
    }

    /**
     * Inserts or updates a single entity and returns the entity’s current state.
     */
    @Override
    public E upsertAndFetch(@Nonnull E entity) {
        return getById(upsertAndFetchId(entity));
    }

    /**
     * Batch upsert for an iterable of entities.
     */
    @Override
    public void upsert(@Nonnull Iterable<E> entities) {
        upsert(toStream(entities), defaultBatchSize);
    }

    private sealed interface PartitionKey {}
    private static final class NoOpKey implements PartitionKey {
        private static final NoOpKey INSTANCE = new NoOpKey();
    }
    private static final class InsertKey implements PartitionKey {
        private static final InsertKey INSTANCE = new InsertKey();
    }
    private static final class UpsertKey implements PartitionKey {
        private static final UpsertKey INSTANCE = new UpsertKey();
    }
    private record UpdateKey(@Nonnull Set<Metamodel<?, ?>> fields) implements PartitionKey {
        UpdateKey() {
            this(Set.of()); // All fields.
        }
    }

    /**
     * Batch upsert for an iterable of entities returning a list of IDs.
     */
    @Override
    public List<ID> upsertAndFetchIds(@Nonnull Iterable<E> entities) {
        if (generationStrategy != SEQUENCE) {
            return upsertAndFetchIdsNoSequence(entities);
        }
        if (!primaryKeyColumns.getFirst().sequence().isEmpty()) {
            //
            // The following SQL would be generated if the sequence is non-empty:
            //
            // MERGE INTO table t
            // USING (VALUES (?, ?), (?, ?)) AS src(id, name)
            // ON (t.id = src.id)
            // WHEN MATCHED THEN
            //   UPDATE SET t.name = src.name, t.owner_id = src.owner_id
            // WHEN NOT MATCHED THEN
            //   INSERT (id, name)
            //	  VALUES (NEXT VALUE FOR seq_id, src.name)
            // OUTPUT INSERTED.id;
            //
            // However, this would result in the following error:
            // NEXT VALUE FOR function can only be used with MERGE if it is defined within a default constraint on the target table for insert actions.
            //
            throw new PersistenceException("MSSQLServer does not support combining sequence-based ID generation with fetch mode. " +
                    "Use the column's DEFAULT constraint for sequence values instead.");
        }
        Map<Set<Metamodel<?, ?>>, PreparedQuery> updateQueries = new HashMap<>();
        try {
            var result = new ArrayList<ID>();
            var entityCache = entityCache();
            partitioned(toStream(entities), defaultBatchSize, entity -> {
                if (isUpdate(entity)) {
                    var dirty = getDirty(entity, entityCache.orElse(null));
                    if (dirty.isEmpty()) {
                        return NoOpKey.INSTANCE;
                    }
                    return new UpdateKey(dirty.get());
                } else {
                    return UpsertKey.INSTANCE;
                }
            }, getMaxShapes(), new UpdateKey()).forEach(partition -> {
                switch (partition.key()) {
                    case NoOpKey ignore -> result.addAll(partition.chunk().stream().map(E::id).toList());
                    case InsertKey ignore -> throw new PersistenceException("Unexpected state.");
                    case UpsertKey ignore -> {
                        // Remove from cache entities with non-default PKs (could be updates via MERGE).
                        entityCache.ifPresent(cache -> partition.chunk().stream()
                                .filter(e -> !model.isDefaultPrimaryKey(e.id()))
                                .forEach(e -> cache.remove(e.id())));
                        result.addAll(getUpsertQuery(partition.chunk()).getResultList(model.primaryKeyType()));
                    }
                    case UpdateKey u -> result.addAll(updateAndFetchIds(partition.chunk(),
                            updateQueries.computeIfAbsent(u.fields(), ignore -> prepareUpdateQuery(u.fields())),
                            entityCache.orElse(null)));
                }
            });
            return result;
        } finally {
            closeQuietly(updateQueries.values().stream());
        }
    }

    private Query getUpsertQuery(@Nonnull Iterable<E> entities) {
        var versionAware = new AtomicBoolean();
        assert primaryKeyColumns.size() == 1;
        var primaryKeyColumn = primaryKeyColumns.getFirst();
        String pkName = primaryKeyColumn.qualifiedName(ormTemplate.dialect());
        return intercept(sql -> sql.versionAware(versionAware.getPlain()), () ->
                ormTemplate.query(flatten(raw("""
                    MERGE INTO \0 t
                    USING (\0) AS src(\0)
                    ON (\0)\0\0
                    OUTPUT INSERTED.%s;""".formatted(pkName), model.type(), mergeSelect(entities), mergeSource(), mergeOn(), mergeUpdate(versionAware), mergeInsert())))
                        .managed());
    }

    private List<ID> upsertAndFetchIdsNoSequence(@Nonnull Iterable<E> entities) {
        Map<Set<Metamodel<?, ?>>, PreparedQuery> updateQueries = new HashMap<>();
        LazySupplier<PreparedQuery> insertQuery = new LazySupplier<>(this::prepareInsertQuery);
        LazySupplier<PreparedQuery> upsertQuery = new LazySupplier<>(this::prepareUpsertQuery);
        try {
            var result = new ArrayList<ID>();
            var entityCache = entityCache();
            partitioned(toStream(entities), defaultBatchSize, entity -> {
                if (isUpdate(entity)) {
                    var dirty = getDirty(entity, entityCache.orElse(null));
                    if (dirty.isEmpty()) {
                        return NoOpKey.INSTANCE;
                    }
                    return new UpdateKey(dirty.get());
                } else if (isAutoGeneratedPrimaryKey()) {
                    return InsertKey.INSTANCE;
                } else {
                    return UpsertKey.INSTANCE;
                }
            }, getMaxShapes(), new UpdateKey()).forEach(partition -> {
                switch (partition.key()) {
                    case NoOpKey ignore -> result.addAll(partition.chunk().stream().map(E::id).toList());
                    case InsertKey ignore -> result.addAll(insertAndFetchIds(partition.chunk(), insertQuery.get()));
                    case UpsertKey ignore -> result.addAll(upsertAndFetchIds(partition.chunk(), upsertQuery.get(),
                            entityCache.orElse(null)));
                    case UpdateKey u -> result.addAll(updateAndFetchIds(partition.chunk(),
                            updateQueries.computeIfAbsent(u.fields(), ignore -> prepareUpdateQuery(u.fields())),
                            entityCache.orElse(null)));
                }
            });
            return result;
        } finally {
            closeQuietly(Stream.of(
                            updateQueries.values().stream(),
                            insertQuery.value().stream(),
                            upsertQuery.value().stream()
                    )
                    .flatMap(identity()));
        }
    }

    /**
     * Batch upsert for an iterable of entities returning the updated entities.
     */
    @Override
    public List<E> upsertAndFetch(@Nonnull Iterable<E> entities) {
        return findAllById(upsertAndFetchIds(entities));
    }

    /**
     * Batch upsert for a stream of entities.
     */
    @Override
    public void upsert(@Nonnull Stream<E> entities) {
        upsert(entities, defaultBatchSize);
    }

    /**
     * Batch upsert for a stream of entities in configurable batch sizes.
     */
    @Override
    public void upsert(@Nonnull Stream<E> entities, int batchSize) {
        Map<Set<Metamodel<?, ?>>, PreparedQuery> updateQueries = new HashMap<>();
        LazySupplier<PreparedQuery> insertQuery = new LazySupplier<>(this::prepareInsertQuery);
        LazySupplier<PreparedQuery> upsertQuery = new LazySupplier<>(this::prepareUpsertQuery);
        try {
            var entityCache = entityCache();
            partitioned(entities, batchSize, entity -> {
                if (isUpdate(entity)) {
                    var dirty = getDirty(entity, entityCache.orElse(null));
                    if (dirty.isEmpty()) {
                        return NoOpKey.INSTANCE;
                    }
                    return new UpdateKey(dirty.get());
                } else if (isAutoGeneratedPrimaryKey()) {
                    return InsertKey.INSTANCE;
                } else {
                    return UpsertKey.INSTANCE;
                }
            }, getMaxShapes(), new UpdateKey()).forEach(partition -> {
                switch (partition.key()) {
                    case NoOpKey ignore -> {}
                    case InsertKey ignore -> insert(partition.chunk(), insertQuery.get());
                    case UpsertKey ignore -> upsert(partition.chunk(), upsertQuery.get(),
                            entityCache.orElse(null));
                    case UpdateKey u -> update(partition.chunk(),
                            updateQueries.computeIfAbsent(u.fields(), ignore -> prepareUpdateQuery(u.fields())),
                            entityCache.orElse(null));
                }
            });
        } finally {
            closeQuietly(Stream.of(
                    updateQueries.values().stream(),
                    insertQuery.value().stream(),
                    upsertQuery.value().stream()
            )
                    .flatMap(identity()));
        }
    }

    private boolean isUpdate(@Nonnull E entity) {
        return isAutoGeneratedPrimaryKey() && !model.isDefaultPrimaryKey(entity.id());
    }

    private PreparedQuery prepareUpsertQuery() {
        var bindVars = ormTemplate.createBindVars();
        var versionAware = new AtomicBoolean();
        return intercept(sql -> sql.versionAware(versionAware.getPlain()), () ->
                ormTemplate.query(flatten(raw("""
                    MERGE INTO \0 t
                    USING (\0) src
                    ON (\0)\0\0;""", model.type(), mergeSelect(bindVars), mergeOn(), mergeUpdate(versionAware), mergeInsert())))
                        .managed().prepare());
    }

    private void upsert(@Nonnull List<E> batch, @Nonnull PreparedQuery query, @Nullable EntityCache<E, ID> cache) {
        if (batch.isEmpty()) {
            return;
        }
        batch.stream().map(this::validateUpsert).forEach(query::addBatch);
        if (cache != null) {
            batch.stream()
                    .filter(e -> !model.isDefaultPrimaryKey(e.id()))
                    .forEach(e -> cache.remove(e.id()));
        }
        int[] result = query.executeBatch();
        if (IntStream.of(result).anyMatch(r -> r != 0 && r != 1 && r != 2)) {
            throw new PersistenceException("Batch upsert failed.");
        }
    }

    private List<ID> upsertAndFetchIds(@Nonnull List<E> batch, @Nonnull PreparedQuery query, @Nullable EntityCache<E, ID> cache) {
        if (batch.isEmpty()) {
            return List.of();
        }
        batch.stream().map(this::validateUpsert).forEach(query::addBatch);
        if (cache != null) {
            batch.stream()
                    .filter(e -> !model.isDefaultPrimaryKey(e.id()))
                    .forEach(e -> cache.remove(e.id()));
        }
        int[] result = query.executeBatch();
        if (IntStream.of(result).anyMatch(r -> r != 0 && r != 1 && r != 2)) {
            throw new PersistenceException("Batch upsert failed.");
        }
        if (isAutoGeneratedPrimaryKey()) {
            try (var generatedKeys = query.getGeneratedKeys(model.primaryKeyType())) {
                return generatedKeys.toList();
            }
        }
        return batch.stream().map(Entity::id).toList();
    }

    @Override
    public ID insertAndFetchId(@Nonnull E entity) {
        if (generationStrategy != SEQUENCE) {
            return super.insertAndFetchId(entity);
        }
        validateInsert(entity);
        assert primaryKeyColumns.size() == 1;
        var primaryKeyColumn = primaryKeyColumns.getFirst();
        String pkName = primaryKeyColumn.qualifiedName(ormTemplate.dialect());
        try (var query = ormTemplate.query(raw("""
                INSERT INTO \0
                OUTPUT INSERTED.%s
                VALUES \0""".formatted(pkName), model.type(), entity)).managed().prepare()) {
            return query.getSingleResult(model.primaryKeyType());
        }
    }

    @Override
    public List<ID> insertAndFetchIds(@Nonnull Iterable<E> entities) {
        if (generationStrategy == NONE) {
            return super.insertAndFetchIds(entities);
        }
        // Also use MSSQLServer specific logic for AUTO_INCREMENT as MSSQLServer does not support generated keys in batch mode.
        entities.forEach(this::validateInsert);
        assert primaryKeyColumns.size() == 1;
        var primaryKeyColumn = primaryKeyColumns.getFirst();
        String pkName = primaryKeyColumn.qualifiedName(ormTemplate.dialect());
        var query = ormTemplate.query(raw("""
            INSERT INTO \0
            OUTPUT INSERTED.%s
            VALUES \0""".formatted(pkName), model.type(), entities))
                .managed();
        return query.getResultList(model.primaryKeyType());
    }
}